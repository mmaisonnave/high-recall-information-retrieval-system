{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ccb0dc",
   "metadata": {},
   "source": [
    "### LABELED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb9b49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114,492\n"
     ]
    }
   ],
   "source": [
    "from utils.models import DataItem\n",
    "lines =open('/home/ec2-user/SageMaker/mariano/notebooks/05. High Recall V2/labeled_data.csv','r').read().splitlines()[1:]\n",
    "lines = [line.split(';') for line in lines ]\n",
    "lines[:3]\n",
    "labeled_data = [DataItem(id_) for id_,_ in lines]\n",
    "\n",
    "idx = 0\n",
    "for id_,label in lines:\n",
    "        item = labeled_data[idx]\n",
    "        idx+=1\n",
    "        assert item.id_ == id_\n",
    "        if label == 'R':\n",
    "            item.set_relevant()\n",
    "        else:\n",
    "            item.set_irrelevant()\n",
    "            assert label=='I'\n",
    "\n",
    "\n",
    "lines = open('./auxiliary_notebooks/in_canada.csv', 'r').read().splitlines()\n",
    "irrelevants = [DataItem(line.split(';')[0]) for line in lines if line.split(';')[1]=='False']\n",
    "for item in irrelevants:\n",
    "    item.set_irrelevant()\n",
    "labeled_data = labeled_data + irrelevants\n",
    "print(f'{len(labeled_data):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aafd04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END C=0.5; accuracy: (test=0.994) f1: (test=0.496) precision: (test=0.424) recall: (test=0.598) total time= 1.1min\n",
      "[CV 2/5] END C=0.5; accuracy: (test=0.998) f1: (test=0.682) precision: (test=1.000) recall: (test=0.517) total time= 1.2min\n",
      "[CV 3/5] END C=0.5; accuracy: (test=0.997) f1: (test=0.628) precision: (test=0.964) recall: (test=0.466) total time= 1.2min\n",
      "[CV 4/5] END C=0.5; accuracy: (test=0.998) f1: (test=0.674) precision: (test=1.000) recall: (test=0.509) total time= 1.2min\n",
      "[CV 5/5] END C=0.5; accuracy: (test=0.998) f1: (test=0.718) precision: (test=1.000) recall: (test=0.560) total time= 1.2min\n",
      "[CV 1/5] END C=1; accuracy: (test=0.992) f1: (test=0.485) precision: (test=0.371) recall: (test=0.701) total time= 1.6min\n",
      "[CV 2/5] END C=1; accuracy: (test=0.998) f1: (test=0.746) precision: (test=1.000) recall: (test=0.595) total time= 1.5min\n",
      "[CV 3/5] END C=1; accuracy: (test=0.998) f1: (test=0.692) precision: (test=0.928) recall: (test=0.552) total time= 1.5min\n",
      "[CV 4/5] END C=1; accuracy: (test=0.998) f1: (test=0.697) precision: (test=1.000) recall: (test=0.534) total time= 1.5min\n",
      "[CV 5/5] END C=1; accuracy: (test=0.998) f1: (test=0.766) precision: (test=1.000) recall: (test=0.621) total time= 2.1min\n",
      "[CV 1/5] END C=5; accuracy: (test=0.991) f1: (test=0.470) precision: (test=0.332) recall: (test=0.803) total time= 2.5min\n",
      "[CV 2/5] END C=5; accuracy: (test=0.998) f1: (test=0.768) precision: (test=0.897) recall: (test=0.672) total time= 3.7min\n",
      "[CV 3/5] END C=5; accuracy: (test=0.998) f1: (test=0.764) precision: (test=0.844) recall: (test=0.698) total time= 3.5min\n",
      "[CV 4/5] END C=5; accuracy: (test=0.998) f1: (test=0.732) precision: (test=0.910) recall: (test=0.612) total time= 3.4min\n",
      "[CV 5/5] END C=5; accuracy: (test=0.999) f1: (test=0.849) precision: (test=0.978) recall: (test=0.750) total time= 3.8min\n",
      "[CV 1/5] END C=7; accuracy: (test=0.991) f1: (test=0.470) precision: (test=0.332) recall: (test=0.803) total time= 2.5min\n",
      "[CV 2/5] END C=7; accuracy: (test=0.998) f1: (test=0.757) precision: (test=0.867) recall: (test=0.672) total time= 3.8min\n",
      "[CV 3/5] END C=7; accuracy: (test=0.998) f1: (test=0.771) precision: (test=0.862) recall: (test=0.698) total time= 4.1min\n",
      "[CV 4/5] END C=7; accuracy: (test=0.998) f1: (test=0.727) precision: (test=0.878) recall: (test=0.621) total time= 4.0min\n",
      "[CV 5/5] END C=7; accuracy: (test=0.999) f1: (test=0.841) precision: (test=0.956) recall: (test=0.750) total time= 4.0min\n",
      "[CV 1/5] END C=15; accuracy: (test=0.990) f1: (test=0.466) precision: (test=0.324) recall: (test=0.829) total time= 2.6min\n",
      "[CV 2/5] END C=15; accuracy: (test=0.998) f1: (test=0.743) precision: (test=0.830) recall: (test=0.672) total time= 4.1min\n",
      "[CV 3/5] END C=15; accuracy: (test=0.998) f1: (test=0.774) precision: (test=0.854) recall: (test=0.707) total time= 4.1min\n",
      "[CV 4/5] END C=15; accuracy: (test=0.998) f1: (test=0.726) precision: (test=0.859) recall: (test=0.629) total time= 4.1min\n",
      "[CV 5/5] END C=15; accuracy: (test=0.998) f1: (test=0.831) precision: (test=0.945) recall: (test=0.741) total time= 4.3min\n",
      "[CV 1/5] END C=50; accuracy: (test=0.990) f1: (test=0.466) precision: (test=0.324) recall: (test=0.829) total time= 2.6min\n",
      "[CV 2/5] END C=50; accuracy: (test=0.998) f1: (test=0.751) precision: (test=0.825) recall: (test=0.690) total time= 4.2min\n",
      "[CV 3/5] END C=50; accuracy: (test=0.998) f1: (test=0.774) precision: (test=0.854) recall: (test=0.707) total time= 4.3min\n",
      "[CV 4/5] END C=50; accuracy: (test=0.998) f1: (test=0.719) precision: (test=0.839) recall: (test=0.629) total time= 4.3min\n",
      "[CV 5/5] END C=50; accuracy: (test=0.998) f1: (test=0.812) precision: (test=0.923) recall: (test=0.724) total time= 4.3min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "params = {'C':[0.5, 1, 5, 7, 15, 50]}\n",
    "GS = GridSearchCV(\n",
    "                  SVC(kernel='poly'),\n",
    "                  params\n",
    "                  ,scoring=['f1','accuracy','precision', 'recall'], \n",
    "                  cv=5,\n",
    "                  verbose=4, \n",
    "                  refit='f1')    \n",
    "\n",
    "X = DataItem.get_X(labeled_data, type_=DataItem.TYPE_GLOVE600)\n",
    "y = DataItem.get_y(labeled_data)\n",
    "rta = GS.fit(X,y)\n",
    "df = (pd.DataFrame(rta.cv_results_)[[\"params\",\"mean_test_accuracy\", \"mean_test_precision\",\"mean_test_recall\",\"mean_test_f1\"]])\n",
    "df.columns=['params','mean accuracy', 'mean precision','mean recall','mean f1',]\n",
    "print(df)\n",
    "info(f'Best Params: {df.best_params_}')\n",
    "# clf_g600 = GS.best_estimator_\n",
    "\n",
    "# del(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb875442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, kernel='poly', probability=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    " \n",
    "\n",
    "X = DataItem.get_X(labeled_data, type_=DataItem.TYPE_GLOVE600)\n",
    "y = DataItem.get_y(labeled_data)\n",
    "\n",
    "clf_g606 = SVC(kernel='poly',C=5, probability=True)\n",
    "\n",
    "clf_g606.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2753cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataItem(id=1323603426, source=GM1, label=U)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "prediction_files = os.listdir('../04. Model of DP/predictions/')\n",
    "suggestions = [DataItem(file_[:-5]) for file_ in  prediction_files]\n",
    "print(suggestions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60492849",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prediction_files = os.listdir('../04. Model of DP/predictions/')\n",
    "# suggestions = [DataItem(file_[:-5]) for file_ in  prediction_files]\n",
    "\n",
    "X = DataItem.get_X(suggestions, type_=DataItem.TYPE_GLOVE600)\n",
    "\n",
    "yhat = clf_g606.predict_proba(X)\n",
    "\n",
    "idx=0\n",
    "for item in suggestions:\n",
    "    prediction_file = '../04. Model of DP/predictions/'+item.id_+'_v3.p'\n",
    "    assert os.path.isfile(prediction_file)\n",
    "    \n",
    "    y = pickle.load(open(prediction_file,'rb'))\n",
    "    \n",
    "    assert len(y)==3 and y.shape==(3,) and np.sum(y[1:])==0\n",
    "    y[1] = yhat[idx,1]\n",
    "#     print(y)\n",
    "    pickle.dump(y, open(prediction_file,'wb'))\n",
    "    idx+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba2b46f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96132924, 0.03867076],\n",
       "       [0.85273564, 0.14726436],\n",
       "       [0.02990042, 0.97009958],\n",
       "       [0.2389065 , 0.7610935 ],\n",
       "       [0.16245994, 0.83754006]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe5610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_files = os.listdir('../04. Model of DP/predictions/')\n",
    "# suggestions = [DataItem(file_[:-5]) for file_ in  prediction_files]\n",
    "\n",
    "# X = DataItem.get_X(suggestions, type_=DataItem.TYPE_GLOVE300)\n",
    "\n",
    "# yhat = clf_g300.predict_proba(X)\n",
    "\n",
    "# idx=0\n",
    "# for item in suggestions:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imm",
   "language": "python",
   "name": "imm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
