{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb9ff0f",
   "metadata": {},
   "source": [
    "### Defining paths to data and retrieving filename-source list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da6e2008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192,433 files detected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1237469385.xml', 'GM'), ('1352134238.xml', 'GM'), ('1323706441.xml', 'GM')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "GM_dirpath = '/home/ec2-user/SageMaker/data/The_Globe_and_Mail_with_DP_filter_by_article_type/'\n",
    "TS_dirpath = '/home/ec2-user/SageMaker/data/Toronto_Star_Publication_with_query/'\n",
    "filenames = os.listdir(GM_dirpath) + os.listdir(TS_dirpath)\n",
    "sources = ['GM']*len(os.listdir(GM_dirpath)) + ['TS']*len(os.listdir(TS_dirpath))\n",
    "print(f'{len(filenames):,} files detected.')\n",
    "data = list(zip(filenames, sources))\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f881eebc",
   "metadata": {},
   "source": [
    "### Defining `Schema` for index (only useful if creating new index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32462a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.fields import Schema, TEXT, ID, STORED, DATETIME\n",
    "\n",
    "# STORED: Stored not indexed and not searchable\n",
    "# TEXT: indexed, by default not stored. It also stores postition to allow phrase search.\n",
    "# ID: Indexed, by default not stored. \n",
    "#     Entire unit stored as a whole (not tokenized). Do not store frequency information. bad for scoring\n",
    "# DATETIME: Stores datetime objects (in a compact storable format)\n",
    "\n",
    "schema = Schema(body=TEXT,\n",
    "                file_id=ID(stored=True),\n",
    "                title=TEXT(field_boost=2.0),\n",
    "                source=STORED,\n",
    "                date=DATETIME\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1f4f5",
   "metadata": {},
   "source": [
    "### Loading index (if exists) or creating new empty index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2701455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index\n",
      "Number of documents in index: 192427\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from lxml import etree\n",
    "\n",
    "from whoosh import index\n",
    "\n",
    "index_dirpath = '/home/ec2-user/SageMaker/mariano/notebooks/03. High Recall Retrieval System/index'\n",
    "if not os.path.exists(index_dirpath):\n",
    "    os.mkdir(index_dirpath)\n",
    "    \n",
    "if index.exists_in(index_dirpath):\n",
    "    print('Loading index')\n",
    "    ix = index.open_dir(index_dirpath)\n",
    "else:\n",
    "    print('Creating new index')\n",
    "    ix = index.create_in(index_dirpath, schema)\n",
    "    \n",
    "print(f'Number of documents in index: {ix.doc_count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203fadc",
   "metadata": {},
   "source": [
    "### adding all documents to open index (only if index is empty (doc_count==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdf58668",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 12min 20s, sys: 1min 43s, total: 1h 14min 4s\n",
      "Wall time: 1h 32min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "\n",
    "# We define a function to get the text content that we need from the XML articles available in our dataset\n",
    "def getxmlcontent(root):\n",
    "    if root.find('.//HiddenText') is not None:\n",
    "        return(root.find('.//HiddenText').text)\n",
    "    \n",
    "    elif root.find('.//Text') is not None:\n",
    "        return(root.find('.//Text').text)\n",
    "    \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "if ix.doc_count()==0:\n",
    "    q = input('Are you sure you want to add new elements to the index?')\n",
    "    if 'yes' in q.lower():\n",
    "        \n",
    "        writer = ix.writer()\n",
    "\n",
    "        for filename, source in data:\n",
    "            full_filename = GM_dirpath+filename if source=='GM' else TS_dirpath+filename\n",
    "            tree = etree.parse(full_filename)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            if getxmlcontent(root) is not None:\n",
    "                soup = BeautifulSoup(getxmlcontent(root))\n",
    "                text = soup.get_text()\n",
    "                y,m,d = root.find('.//NumericDate').text.split('-')\n",
    "                date = datetime.datetime(int(y),int(m),int(d))\n",
    "                title = root.find('.//Title').text\n",
    "                source_name = 'Toronto Star' if source=='TS' else 'The Globe and Mail'\n",
    "        #         print(f'Title :\\t\\t{title:20}')\n",
    "        #         print(f'Date  :\\t\\t{str(date):20}')\n",
    "        #         print(f'SRC NM:\\t\\t{source_name:20}')\n",
    "        #         print(f'Text :\\t\\t{text[:100]:20}')\n",
    "        #         print(f'ID   :\\t\\t{filename}')\n",
    "\n",
    "                writer.add_document(title=title, \n",
    "                                    body=text, \n",
    "                                    file_id=filename,\n",
    "                                    source=source_name,\n",
    "                                    date=date\n",
    "                                   )\n",
    "\n",
    "        # schema = Schema(body=TEXT,\n",
    "        #                 file_id=ID(stored=True),\n",
    "        #                 title=TEXT(field_boost=2.0),\n",
    "        #                 source=STORED,\n",
    "        #                 date=DATETIME\n",
    "        #                )\n",
    "            else:\n",
    "                text = 'Error in processing document'\n",
    "\n",
    "\n",
    "\n",
    "        writer.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90735400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4G\tindex/\r\n"
     ]
    }
   ],
   "source": [
    "!du -hs index/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abddff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searcher = ix.searcher()\n",
    "# searcher.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed7a7deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Hit {'file_id': '1140932582.xml', 'source': 'The Globe and Mail'}>\n",
      "<Hit {'file_id': '437132719.xml', 'source': 'Toronto Star'}>\n",
      "<Hit {'file_id': '1140932027.xml', 'source': 'The Globe and Mail'}>\n",
      "<Hit {'file_id': '1140923310.xml', 'source': 'The Globe and Mail'}>\n",
      "<Hit {'file_id': '437138434.xml', 'source': 'Toronto Star'}>\n",
      "<Hit {'file_id': '1140931445.xml', 'source': 'The Globe and Mail'}>\n",
      "<Hit {'file_id': '1140926088.xml', 'source': 'The Globe and Mail'}>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Top 7 Results for And([Or([Term('title', 'refugee'), Term('body', 'refugee')]), NumericRange('date', 62920195200000000, 62920367999999999, False, False, boost=1.0, constantscore=True)]) runtime=0.010276828000314708>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from whoosh.qparser import MultifieldParser\n",
    "\n",
    "mp = MultifieldParser(['title','body'],schema=ix.schema)\n",
    "q = mp.parse(u'Refugee and date:[19941112 TO 19941113]')\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    results = s.search(q)\n",
    "    for result in results:\n",
    "        print(result)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90edc1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "QueryParser?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cd85790",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ix.searcher()\n",
    "s.search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a72fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imm",
   "language": "python",
   "name": "imm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
