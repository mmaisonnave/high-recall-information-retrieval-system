{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ff7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# INPUT FILES  #\n",
    "################\n",
    "labeled_datafile = '/home/ec2-user/SageMaker/mariano/datasets/multiculturalism/files/labeled_data.csv'\n",
    "unlabeled_datafile = '/home/ec2-user/SageMaker/serperi/system/sessions/scal/One_second_round/data/exported_data_2022-11-23_00-18.csv'\n",
    "\n",
    "################\n",
    "# OUTPUT FILES #\n",
    "################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e000de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ec2-user/SageMaker/mariano/repositories/tdmstudio-high-recall-information-retrieval-system/')\n",
    "from utils import io\n",
    "from utils import tdmstudio\n",
    "\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2f1013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-24 13:55:38.353905 [ \u001b[1;94mINFO\u001b[0m  ] Appending texts ...\n",
      "2023-02-24 13:56:04.052687 [  \u001b[1;92mOK\u001b[0m   ] Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1151636504</td>\n",
       "      <td>R</td>\n",
       "      <td>Not just folklore--a tool for trade.\\n        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1237806961</td>\n",
       "      <td>I</td>\n",
       "      <td>Multiculturalism fine in theory.\\n          \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1269975477</td>\n",
       "      <td>I</td>\n",
       "      <td>CRTC deflates promoters of multicultural TV ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1143676333</td>\n",
       "      <td>I</td>\n",
       "      <td>The myth of Canada as cultural mosaic.\\n      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1143862565</td>\n",
       "      <td>I</td>\n",
       "      <td>Display Ad 19 -- No Title.\\n          \\n      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id label                                               text\n",
       "0  1151636504     R  Not just folklore--a tool for trade.\\n        ...\n",
       "1  1237806961     I  Multiculturalism fine in theory.\\n          \\n...\n",
       "2  1269975477     I  CRTC deflates promoters of multicultural TV ch...\n",
       "3  1143676333     I  The myth of Canada as cultural mosaic.\\n      ...\n",
       "4  1143862565     I  Display Ad 19 -- No Title.\\n          \\n      ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################\n",
    "# READING LABELED AND UNLABELED DATA #\n",
    "######################################\n",
    "\n",
    "# Read labeled data\n",
    "labeled_df = pd.read_csv(labeled_datafile)\n",
    "labeled_df\n",
    "# Change ID to str type\n",
    "labeled_df['id']=[str(id_) for id_ in labeled_df['id']]\n",
    "\n",
    "# Everything has to be either Relevant or Irrelevant (not unknown)\n",
    "assert all([label=='R' or label=='I' for label in labeled_df['label']])\n",
    "\n",
    "io.info('Appending texts ...')\n",
    "labeled_df['text']=[tdmstudio.get_title_and_text(tdmstudio.get_filename(id_)) for id_ in labeled_df['id']]\n",
    "io.ok('Done')\n",
    "\n",
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Reading unlabeled (to make predictions)\n",
    "# unlabeled_df = pd.read_csv(unlabeled_datafile)\n",
    "\n",
    "# #Building id from URL \n",
    "# unlabeled_df['id'] = [re.sub('https://proquest.com/docview/','' ,url ) for url in unlabeled_df['URL']]\n",
    "\n",
    "\n",
    "# io.info(f'labeled_df.shape=       {labeled_df.shape}')\n",
    "# io.info(f'unlabeled_df.shape=     {unlabeled_df.shape}')\n",
    "# print()\n",
    "\n",
    "# # FILTERING, ONLY KEEPING SUGGESTIONS, NOT LABELED #\n",
    "# io.info(f'Removing labeled from suggestions (unlabeled) ...')\n",
    "# unlabeled_df=unlabeled_df[unlabeled_df['relevant_or_suggested']=='sugg']\n",
    "# io.info(f'new unlabeled_df.shape= {unlabeled_df.shape}')\n",
    "\n",
    "# # REMOVING LABELED DURING EVALUATION #\n",
    "# io.info(f'Removing labeled from unlabeled ...')\n",
    "# labeled_ids=set(labeled_df['id'])\n",
    "# unlabeled_df = unlabeled_df[[id_ not in labeled_ids for id_ in unlabeled_df['id']]]\n",
    "# io.info(f'new unlabeled_df.shape= {unlabeled_df.shape}')\n",
    "\n",
    "# ########################################\n",
    "# # READING TITLE AND TEXT FOR ALL ITEMS #\n",
    "# ########################################\n",
    "# print()\n",
    "\n",
    "# unlabeled_df['text']=[tdmstudio.get_title_and_text(tdmstudio.get_filename(id_)) for id_ in unlabeled_df['id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2f4be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-24 13:59:15.677404 [ \u001b[1;94mINFO\u001b[0m  ] Creating labeled articles representation ...\n",
      "2023-02-24 14:00:14.817065 [ \u001b[1;94mINFO\u001b[0m  ] Training model ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import nlp_auxiliary\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stopwords = {stopword for stopword in nlp.Defaults.stop_words if stopword==nlp_auxiliary.preprocessor(stopword)}\n",
    "vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                             preprocessor=nlp_auxiliary.preprocessor,\n",
    "                             stop_words=stopwords,\n",
    "                             ngram_range=(1,3),\n",
    "                             max_features=10000,\n",
    "                             use_idf=True,                             \n",
    "                             smooth_idf=True,                             \n",
    "                            )\n",
    "\n",
    "io.info('Creating labeled articles representation ...')\n",
    "X = vectorizer.fit_transform(labeled_df['text'])\n",
    "y = np.array([1 if label=='R' else 0 for label in labeled_df['label']])\n",
    "\n",
    "io.info('Training model ...')\n",
    "model = LogisticRegression(keep_pr)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee29024a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with file=17k.csv (shape=(17014, 1))\n",
      "Adding text ...\n",
      "Building X\n",
      "prediction\n",
      "Droping text ...\n",
      "Output to 17k_with_predictions.csv\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for file_ in ['8k.csv', '17k.csv']:\n",
    "    unlabeled = pd.read_csv(file_,header=None)\n",
    "    print(f'Working with file={file_} (shape={unlabeled.shape})')\n",
    "    unlabeled.columns=['id']\n",
    "    print('Adding text ...')\n",
    "    unlabeled['text']=[tdmstudio.get_title_and_text(tdmstudio.get_filename(str(id_))) for id_ in unlabeled['id']]\n",
    "    unlabeled.head()\n",
    "\n",
    "    print('Building X')\n",
    "    X = vectorizer.transform(unlabeled['text'])\n",
    "    print('prediction')\n",
    "    yhat = model.predict_proba(X)\n",
    "    unlabeled['yhat']=yhat[:,1]\n",
    "    output_file = file_.split('.')[0]+'_with_predictions'+'.csv'\n",
    "    \n",
    "    print('Droping text ...')\n",
    "    unlabeled=unlabeled.drop(columns=['text'])    \n",
    "    print(f'Output to {output_file}')\n",
    "    \n",
    "    unlabeled.to_csv(output_file)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7393052d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8115, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18cdc29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'17k_with_predictions.csv'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9226697f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'17k_with_predictions.csv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_='17k.csv'\n",
    "output_file = file_.split('.')[0]+'_with_predictions'+'.csv'\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ed9270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imm",
   "language": "python",
   "name": "imm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
