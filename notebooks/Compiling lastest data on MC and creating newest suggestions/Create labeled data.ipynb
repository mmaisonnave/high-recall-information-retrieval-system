{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04701bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First round:              315 (relevant= 12)\n",
      "Second round:             290 (relevant= 49)\n",
      "--\n",
      "First evaluation:         100 (relevant= 29)\n",
      "Second evaluation:         50 (relevant= 14)\n",
      "--\n",
      "Shared between first evaluation and second round:      16\n",
      "Shared between first evaluation and second evaluation: 2\n",
      "--\n",
      "All data with no dups 737 - conflicts=6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "############################################\n",
    "# ~ LABELED DATA FOR ROUND 1 and ROUND 2 ~ #\n",
    "############################################\n",
    "labeled_datafile= '/home/ec2-user/SageMaker/serperi/system/sessions/scal/One_second_round/data/labeled_data2022-11-23_00-18.csv'\n",
    "df = pd.read_csv(labeled_datafile, sep=';',header=None)\n",
    "df.head()\n",
    "df = df.rename(columns={0:'id',1:'label'} )\n",
    "\n",
    "first_round=df.iloc[:315,:]\n",
    "second_round=df.iloc[315:,:]\n",
    "relevant_in_first_round = len([label for label in first_round['label'] if label=='R'])\n",
    "relevant_in_second_round = len([label for label in second_round['label'] if label=='R'])\n",
    "\n",
    "print(f'First round:       {len(first_round):10} (relevant={relevant_in_first_round:3})')\n",
    "print(f'Second round:      {len(second_round):10} (relevant={relevant_in_second_round:3})')\n",
    "print('--')\n",
    "\n",
    "assert first_round.shape[0]==len(set(first_round['id']))\n",
    "assert second_round.shape[0]==len(set(second_round['id']))\n",
    "\n",
    "########################################################\n",
    "# ~ LABELED DATA FROM EVALUATION ROUND 1 and ROUND 2 ~ #\n",
    "########################################################\n",
    "evaluation50_file = 'evaluation50.csv'\n",
    "evaluation100_file = 'evaluation100.csv'\n",
    "\n",
    "first_evaluation = pd.read_csv(evaluation100_file, sep=';')\n",
    "second_evaluation = pd.read_csv(evaluation50_file, sep=';')\n",
    "\n",
    "relevant_in_first_evaluation = len([label for label in first_evaluation['label'] if label=='R'])\n",
    "relevant_in_second_evaluation = len([label for label in second_evaluation['label'] if label=='R'])\n",
    "                                \n",
    "print(f'First evaluation:  {len(first_evaluation):10} (relevant={relevant_in_first_evaluation:3})')\n",
    "print(f'Second evaluation: {len(second_evaluation):10} (relevant={relevant_in_second_evaluation:3})')\n",
    "print('--')\n",
    "\n",
    "\n",
    "assert first_evaluation.shape[0]==len(set(first_evaluation['id']))\n",
    "assert second_evaluation.shape[0]==len(set(second_evaluation['id']))\n",
    "\n",
    "##############\n",
    "# ~ SHARED ~ #\n",
    "##############\n",
    "R1 = set(first_round['id'])\n",
    "R2 = set(second_round['id'])\n",
    "\n",
    "E1 = set(first_evaluation['id'])\n",
    "E2 = set(second_evaluation['id'])\n",
    "print(f'Shared between first evaluation and second round:      {len(E1.intersection(R2))}')\n",
    "print(f'Shared between first evaluation and second evaluation: {len(E1.intersection(E2))}')\n",
    "print('--')\n",
    "###########\n",
    "# ~ ALL ~ #\n",
    "###########\n",
    "all_data_with_dups = first_round.append(first_evaluation).append(second_round).append(second_evaluation)\n",
    "# all_data.shape\n",
    "\n",
    "d = {}\n",
    "conflicts=0\n",
    "for i in range(all_data_with_dups.shape[0]):\n",
    "    id_, label = all_data_with_dups.iloc[i,]\n",
    "    if id_ in d and d[id_]!=label: # We already saw this item with a different label.\n",
    "        d[id_]='U'\n",
    "        conflicts+=1\n",
    "    else:\n",
    "        d[id_]=label\n",
    "\n",
    "print(f'All data with no dups {len(d)} - conflicts={conflicts}')\n",
    "\n",
    "items = d.items()\n",
    "all_data = pd.DataFrame({'id': [key  for key,value in items ],\n",
    "                         'label':[value for key,value in items]\n",
    "                        })\n",
    "\n",
    "conflicting_data = {1237561744:'R',\n",
    "                    1237268511:'R',\n",
    "                    1444938912:'R',\n",
    "                    1444939955:'I',\n",
    "                    1143705076:'R',\n",
    "                    1237792063:'I',\n",
    "                   }\n",
    "for id_ in conflicting_data:\n",
    "    all_data.loc[all_data['id']==id_,'label']=conflicting_data[id_]\n",
    "\n",
    "all_data.head()\n",
    "\n",
    "all_data.to_csv('/home/ec2-user/SageMaker/mariano/datasets/multiculturalism/files/labeled_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imm",
   "language": "python",
   "name": "imm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
