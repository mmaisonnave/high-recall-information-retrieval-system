{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f17b752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab)=             10,000 ([canada, year, ..., multicultural, multiculturalism])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'XML': 'data/GM_files/1282745265.xml',\n",
       " 'pickle': 'data/precomputed/1282745265_representations.p',\n",
       " 'vector': <1x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 96 stored elements in Compressed Sparse Row format>}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "data = {}\n",
    "# XML FILES (30.000)\n",
    "data_folder = 'data/GM_files/'\n",
    "for file in os.listdir(data_folder):\n",
    "    id_ = file.split('.')[0]\n",
    "    data[id_]={}\n",
    "    data[id_]['XML']=os.path.join(data_folder,file)\n",
    "\n",
    "precomputed_folder = 'data/precomputed/'\n",
    "for file in os.listdir(precomputed_folder) :\n",
    "    id_=file.split('_')[0]\n",
    "    if id_ in data:\n",
    "        data[id_]['pickle'] = os.path.join(precomputed_folder,file)\n",
    "        data[id_]['vector'] = pickle.load(open(data[id_]['pickle'], 'rb'))['BoW']\n",
    "\n",
    "\n",
    "# VOCAB\n",
    "vocab = np.array(open('data/vocab.txt','r').read().splitlines())\n",
    "print(f'len(vocab)=             {len(vocab):,} ([{vocab[0]}, {vocab[1]}, ..., {vocab[-2]}, {vocab[-1]}])')\n",
    "\n",
    "data['1282745265']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc004693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1811409664', '1282745265', '1242415170']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9f3758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tdmstudio import get_title_and_text\n",
    "from utils.tokenizer import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "for id_ in data:\n",
    "    token_list = tokenizer.tokenize(get_title_and_text(data[id_]['XML']))\n",
    "    ngram_list = list(token_list)\n",
    "    ngram_list += [' '.join(ngram) for ngram in Tokenizer.ngrams(ngram_list)]\n",
    "    ngram_list = filter(lambda ngram: ngram in word2index , ngram_list)\n",
    "    data[id_]['ngrams']=ngram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "522493a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = dict([(word,idx) for idx,word in enumerate(vocab)])\n",
    "for id_ in data:\n",
    "    data[id_]['ngrams']=list(data[id_]['ngrams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e65b4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  OK   ] Finished.\n"
     ]
    }
   ],
   "source": [
    "for id_ in data:\n",
    "    contained_words = vocab[data[id_]['vector'].toarray()[0,:]!=0]\n",
    "    assert all([word in data[id_]['ngrams'] for word in contained_words])\n",
    "print('[  OK   ] Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75fb005e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['canada', 'year', 'new', 'ad', 'ing', 'mr', 'include', 'mail',\n",
       "       'ad title', 'globe', 'high', 'display ad', 'ment', 'look', 'group',\n",
       "       'old', 'con', 'close', 'level', 'director', 'ed', 'industry',\n",
       "       'federal', 'official', 'province', 'believe', 'feature', 'note',\n",
       "       'hi', 'vice', 'appear', 'canadians', 'prove', 'individual',\n",
       "       'production', 'hotel', 'operate', 'sun', 'fully', 'security',\n",
       "       'contract', 'pass', 'source', 'asset', 'degree', 'tour',\n",
       "       'probably', 'piece', 'govern ment', 'aid', 'popular', 'particular',\n",
       "       'oi', 'airport', 'ford', 'scotia', 'nature', 'edward', 'entire',\n",
       "       'ww', 'wm', 'trend', 'hire', 'arts', 'champion', 'furniture',\n",
       "       'grey', 'busy', 'motors', 'side', 'ch', 'reader', 'deny',\n",
       "       'imperial', 'avail', 'investigation', 'partnership', 'expertise',\n",
       "       'external', 'harold', 's7', 'wh', 'air condition', 'quit',\n",
       "       'careers', 'delightful', 'masters', 'grove', 'dor',\n",
       "       'royal bank canada', 'gang', 'living dining', 'volkswagen',\n",
       "       'main st', 'barcelona', 'oct nov', 'vac', 'vestor'], dtype='<U30')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_='1282745265'\n",
    "vocab[data[id_]['vector'].toarray()[0,:]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "array(['canada', 'year', 'new', 'title', 'ad', 'ing', 'ad title',\n",
    "       'business', 'display', 'man', 'display ad', 'display ad title',\n",
    "       'offer', 'plan', 'find', 'right', 'open', 'general', 'information',\n",
    "       'live', 'level', 'director', 'industry', 'require', 'problem',\n",
    "       'experience', 'en', 'form', 'range', 'project', 'wide', 'research',\n",
    "       'th', 've', 'industrial', 'recently', 'challenge', 'training',\n",
    "       'ability', 'degree', 'nt', 'responsible', 'council', 'vi', 'fit',\n",
    "       'responsibility', 'ri', 'aid', 'pi', 'technical', 'planning', 'rr',\n",
    "       'ni', 'particular', 'understand', 'engineer', 'background',\n",
    "       'engineering', 'applicant', 'essential', 'nr', 'ha', 'promote',\n",
    "       'su', 'solution', 'method', 'um', 'chemical', 'physical', 'sh',\n",
    "       'brunswick', 'oc', 'jn', 'vv', 'sj', 'sal', 'new brunswick',\n",
    "       'wide range', 'scientific', 'tit', 'kt', 'rk', 'productivity',\n",
    "       'liv', 'stud', 'vh', 'nnd', 'bn', 'thp', 'duties', 'ker', 'gh',\n",
    "       'peri', 'ath', 'sti', 'irv'], dtype='<U30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05c972bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display Ad 47 -- No Title.\n",
      "          \n",
      "            \n",
      "\n",
      "Â \n",
      "\n",
      "NEW BRUNSWICK RESEARCH AND PRODUCTIVITY COUNCIL requires KXr Su ve applicant sh uM ive scientific or engineering background of years' Jn scientific or industrial ri understanding nt Industrial and -dme Ability to plan find ath experience fit responsible level is essential Council is recently formed and offers challenge to right man Director will ha wide range of responsibilities from the general Council business to the planning and at on of thp 'meH s Research and Pi Programmes Sal irv open TKCllMCAl INFORMATION pi-l kar sti -uM live degree in physical rr In chemical or rr engineering some training In industrial engineering or business  vi nnd some In Industry Duties U'Hild he twofold Firstly to as Kt liv th oC In the solution of technical Industrial problems aid to promote thp Council's Project 1'i vri Sj rir d industrial en tit ni vV and method stud Sihry ' p peri nr vH -j if -it -ni Ker gh Ing full particular Neir Brtjnn rk Research nnd PmdcrtMty CnqovU Bn 123A. Frederleton Canada\n",
      "\n",
      "            \n",
      "          \n",
      ".\n"
     ]
    }
   ],
   "source": [
    "print(get_title_and_text(data[id_]['XML']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2eac444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_='1282745265'\n",
    "data[id_]\n",
    "token_list = tokenizer.tokenize(get_title_and_text(data[id_]['XML']))\n",
    "list(token_list)\n",
    "'include' in token_list\n",
    "ngram_list = list(token_list)\n",
    "ngram_list += [' '.join(ngram) for ngram in Tokenizer.ngrams(ngram_list)]\n",
    "ngram_list = filter(lambda ngram: ngram in word2index , ngram_list)\n",
    "'include' in ngram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3bc5bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['canada', 'year', 'new', 'ad', 'ing', 'mr', 'include', 'mail',\n",
       "       'ad title', 'globe', 'high', 'display ad', 'ment', 'look', 'group',\n",
       "       'old', 'con', 'close', 'level', 'director', 'ed', 'industry',\n",
       "       'federal', 'official', 'province', 'believe', 'feature', 'note',\n",
       "       'hi', 'vice', 'appear', 'canadians', 'prove', 'individual',\n",
       "       'production', 'hotel', 'operate', 'sun', 'fully', 'security',\n",
       "       'contract', 'pass', 'source', 'asset', 'degree', 'tour',\n",
       "       'probably', 'piece', 'govern ment', 'aid', 'popular', 'particular',\n",
       "       'oi', 'airport', 'ford', 'scotia', 'nature', 'edward', 'entire',\n",
       "       'ww', 'wm', 'trend', 'hire', 'arts', 'champion', 'furniture',\n",
       "       'grey', 'busy', 'motors', 'side', 'ch', 'reader', 'deny',\n",
       "       'imperial', 'avail', 'investigation', 'partnership', 'expertise',\n",
       "       'external', 'harold', 's7', 'wh', 'air condition', 'quit',\n",
       "       'careers', 'delightful', 'masters', 'grove', 'dor',\n",
       "       'royal bank canada', 'gang', 'living dining', 'volkswagen',\n",
       "       'main st', 'barcelona', 'oct nov', 'vac', 'vestor'], dtype='<U30')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[data[id_]['vector'].toarray()[0,:]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57591517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02003962, 0.02228512, 0.02249927, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[id_]['vector'].toarray()[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b7307c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vec = pickle.load(open( 'data/precomputed/1282745265_representations.p', 'rb'))['BoW'].toarray()[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77993b54",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35537/2646682531.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mid_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1282745265'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ngrams'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "id_='1282745265'\n",
    "for word in vocab[data[id_]['vector'].toarray()[0,:]!=0]:\n",
    "    assert word in data[id_]['ngrams']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd43244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "los_30000_ids = set([file.split('.')[0] for file in  os.listdir('data/GM_files')])\n",
    "print(len(los_30000_ids ))\n",
    "\n",
    "precomputed=[os.path.join('data/precomputed',file) for file in os.listdir('data/precomputed/') if not file.split('_')[0] in los_30000_ids]\n",
    "len(precomputed)\n",
    "for file in precomputed:\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99285cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "856299"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "los_30000_ids = set([file.split('.')[0] for file in  os.listdir('data/GM_files')])\n",
    "print(len(los_30000_ids ))\n",
    "\n",
    "precomputed=[os.path.join('data/precomputed',file) for file in os.listdir('data/precomputed/') if not file.split('_')[0] in los_30000_ids]\n",
    "len(precomputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614526ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imm",
   "language": "python",
   "name": "imm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
