{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7aef2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "import datetime\n",
    "def info(str_):\n",
    "    print(f'{datetime.datetime.now()} [ \\033[1;94mINFO\\x1b[0m  ] {str_}')\n",
    "def ok(str_):\n",
    "    print(f'{datetime.datetime.now()} [  \\033[1;92mOK\\x1b[0m   ] {str_}')\n",
    "def warning(str_):\n",
    "    print(f'{datetime.datetime.now()} [\\x1b[1;31mWARNING\\x1b[0m] {str_}')\n",
    "def html(str_=''):\n",
    "    display(HTML(str_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3680845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_date(filename):\n",
    "    tree = etree.parse(filename)\n",
    "    root = tree.getroot()\n",
    "#     title = root.find('.//Title').text\n",
    "    date = root.find('.//NumericDate').text\n",
    "#     publisher = root.find('.//PublisherName').text\n",
    "    assert date is not None\n",
    "    \n",
    "    return date\n",
    "\n",
    "def get_title_and_text(filename):\n",
    "    tree = etree.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    if root.find('.//HiddenText') is not None:\n",
    "        text = (root.find('.//HiddenText').text)\n",
    "\n",
    "    elif root.find('.//Text') is not None:\n",
    "        text = (root.find('.//Text').text)\n",
    "\n",
    "    else:\n",
    "        text = None\n",
    "                       \n",
    "    title = root.find('.//Title')\n",
    "    if title is not None:\n",
    "        title = title.text\n",
    "    if not text is None:\n",
    "        text = BeautifulSoup(text, parser='html.parser').get_text()\n",
    "\n",
    "    return title,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c299987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-22 21:43:38.829135 [ \u001b[1;94mINFO\u001b[0m  ] len(all_files):        2,079,786\n",
      "2022-02-22 21:43:38.829325 [ \u001b[1;94mINFO\u001b[0m  ] len(dp_files):             6,938\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "GM_all_part1 = '/home/ec2-user/SageMaker/data/GM_all_1945_1956/'\n",
    "GM_all_part2 = '/home/ec2-user/SageMaker/data/GM_all_1957-1967/'\n",
    "GM_dp_dirpath = '/home/ec2-user/SageMaker/data/GM_DP_and_Canada1945_1967/'\n",
    "\n",
    "all_files = [GM_all_part1+file_ for file_ in os.listdir(GM_all_part1)]\n",
    "all_files += [GM_all_part2+file_ for file_ in os.listdir(GM_all_part2)]\n",
    "\n",
    "dp_files = [GM_dp_dirpath+file_ for file_ in os.listdir(GM_dp_dirpath)]\n",
    "\n",
    "# GM_dirpath = '/home/ec2-user/SageMaker/data/The_Globe_and_Mail_with_DP_filter_by_article_type/'\n",
    "# all_files = [TS_dirpath+file_id for file_id in os.listdir(TS_dirpath)]\n",
    "# all_files += [GM_dirpath+file_id for file_id in os.listdir(GM_dirpath)]\n",
    "\n",
    "info(f'len(all_files):       {len(all_files):10,}')\n",
    "info(f'len(dp_files):        {len(dp_files):10,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88bade0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.load('en_core_web_lg', disable=['textcat','lemmatizer', 'parser', 'tagger','ner'])\n",
    "\n",
    "def remove_punctuation(word):\n",
    "    return ''.join([char for char in word if not char in string.punctuation+' '])\n",
    "\n",
    "def tokenize(str_):\n",
    "    tokens = [word.text.lower() for word in nlp(str_) if not word.is_stop]\n",
    "    tokens = [word.replace('\\n', '') for word in tokens if not word.isnumeric() and len(remove_punctuation(word))!=0]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "\n",
    "def build_vocab(file_list, umbral=None,threshold=10000):\n",
    "    if os.path.isfile('cache/vocab.p'):\n",
    "        vocab = pickle.load(open('cache/vocab.p', 'rb'))\n",
    "    else:\n",
    "        visited = set()\n",
    "        freq = {}\n",
    "        for file_ in tqdm(file_list):\n",
    "            title, text = get_title_and_text(file_)\n",
    "            tokens = tokenize(title+' '+text)\n",
    "            for token in tokens:\n",
    "                if token in visited:\n",
    "                    if not token in freq:\n",
    "                        freq[token]=2\n",
    "                    else:\n",
    "                        freq[token]+=1\n",
    "                else:\n",
    "                    visited.add(token)\n",
    "        word_frequency_list = [(word, freq[word]) for word in freq if not word.strip()=='' and len(word)>=3]\n",
    "        word_frequency_list = sorted(word_frequency_list, key=lambda x: x[1],reverse=True)\n",
    "        vocab = [word for word,_ in word_frequency_list[:threshold]]\n",
    "\n",
    "        pickle.dump(vocab,open('cache/vocab.p', 'wb'))        \n",
    "        del(freq)\n",
    "        del(word_frequency_list)\n",
    "        del(visited)\n",
    "    return vocab\n",
    "vocab = build_vocab(dp_files)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c56a2bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "word2idx = dict([(word,idx) for idx, word in enumerate(vocab)])\n",
    "\n",
    "\n",
    "\n",
    "def process_file(file_):\n",
    "    output = file_[:-4] + '.bow_vector'\n",
    "    x = np.zeros(shape=(len(vocab)+1), dtype='float32')\n",
    "    title, text = get_title_and_text(file_)\n",
    "\n",
    "    tokens = tokenize(title+' '+text)\n",
    "    for token in tokens:\n",
    "        if token in word2idx:\n",
    "            x[word2idx[token]]+=1\n",
    "        else:\n",
    "            x[-1]+=1\n",
    "\n",
    "    pickle.dump(x, open(output,'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28936c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-22 21:45:06.189658 [ \u001b[1;94mINFO\u001b[0m  ] Starting...\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "info('Starting...')\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    executor.map(process_file, all_files)\n",
    "\n",
    "ok('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e1c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc891def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imm",
   "language": "python",
   "name": "imm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
