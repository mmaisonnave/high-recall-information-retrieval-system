{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158f12b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ec2-user/SageMaker/mariano/repositories/tdmstudio-high-recall-information-retrieval-system/')\n",
    "from utils.data_item import DataItem\n",
    "from utils.oracle import Oracle\n",
    "# unlabeled = Oracle.get_collection()\n",
    "\n",
    "from utils.scal_ui import SCAL_UI\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from utils.scal import SCAL\n",
    "from utils.data_item import QueryDataItem\n",
    "\n",
    "seed = 22127\n",
    "N=1000\n",
    "cap=5\n",
    "\n",
    "def start_system(session_name, topic_description ):\n",
    "    clear_output(wait=False)\n",
    "    if os.path.exists(f'sessions/scal/{session_name}'):\n",
    "        scal = SCAL.from_disk(session_name=session_name)\n",
    "    else:\n",
    "        \n",
    "        # UNLABELED\n",
    "#         data_sources = ['/home/ec2-user/SageMaker/mariano/notebooks/07. Simulation/data/GM_files'\n",
    "#                        ]\n",
    "        data_sources = ['/home/ec2-user/SageMaker/data/GM_not_all_1960_1978',\n",
    "                        '/home/ec2-user/SageMaker/data/GM_not_all_1979_1997',\n",
    "                        '/home/ec2-user/SageMaker/data/GM_not_all_1998_2018',\n",
    "                    ]\n",
    "        files = [os.path.join(data_source,file) for data_source in data_sources for file in os.listdir(data_source) ]\n",
    "#         print(f'Total number of files: {len(files):,}')\n",
    "\n",
    "        \n",
    "        def unlabeled_from_data_source(data_source):\n",
    "            return [DataItem(name.split('.')[0]) for name in os.listdir(data_source)]\n",
    "        \n",
    "        unlabeled = [elem for list_ in list(map(unlabeled_from_data_source, data_sources)) for elem in list_]\n",
    "#         unlabeled = list(filter(lambda x: x.has_vector(), unlabeled))\n",
    "        # LABELED\n",
    "#         print(topic_description)\n",
    "        doc = QueryDataItem(topic_description)\n",
    "        doc.set_relevant()\n",
    "        scal = SCAL(session_name, \n",
    "                    [doc], \n",
    "                    unlabeled,\n",
    "                    random_sample_size=N,\n",
    "                    batch_size_cap=cap,\n",
    "                    simulation=False, \n",
    "                    seed=seed)\n",
    "    scal.run()\n",
    "    \n",
    "_=SCAL_UI(start_system)\n",
    "\n",
    "# import ipywidgets as widgets\n",
    "# combobox = widgets.Combobox(options=['1','2','3',])\n",
    "# def do_something(widget=None):\n",
    "#     print('submit')\n",
    "# combobox.on_submit(do_something)\n",
    "# combobox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bafb9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9ab9f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new', 'york', 'times', 'new york', 'york times', 'new york times']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.tokenizer import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "# Tokenizer.ngrams(list(tokenizer.tokenize()))\n",
    "\n",
    "token_list = tokenizer.tokenize('New York Times')   # With lower case lemmatization works different and \n",
    "                                                    # New York Times trigrams is missed.\n",
    "ngram_list = list(token_list)\n",
    "ngram_list += [' '.join(ngram) for ngram in Tokenizer.ngrams(ngram_list)]\n",
    "ngram_list = filter(lambda ngram: ngram in QueryDataItem.word2index , ngram_list)\n",
    "list(ngram_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d5ee95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab)=10000\n",
      "Topic description: new york times \n",
      "Vector norm:       1.000\n",
      "N-grams:           ['new' 'time' 'york' 'new york']\n",
      "Weights:           [0.24018316 0.30329878 0.55767806 0.73438211]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.data_item import QueryDataItem\n",
    "vocab = np.array(QueryDataItem.vocab)\n",
    "print(f'len(vocab)={len(vocab)}')\n",
    "\n",
    "syn=QueryDataItem('new york times')\n",
    "print(f'Topic description: {syn.text}')\n",
    "print(f'Vector norm:       {np.linalg.norm(syn.vector()):4.3f}')\n",
    "print(f'N-grams:           {vocab[syn.vector()!=0]}')\n",
    "print(f'Weights:           {syn.vector()[syn.vector()!=0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ba9cca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(files)=2961906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<utils.data_item.DataItem at 0x7f144a4c0430>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sources = ['/home/ec2-user/SageMaker/data/GM_not_all_1960_1978',\n",
    "                '/home/ec2-user/SageMaker/data/GM_not_all_1979_1997',\n",
    "                '/home/ec2-user/SageMaker/data/GM_not_all_1998_2018',\n",
    "            ]\n",
    "files = [os.path.join(data_source,file) for data_source in data_sources for file in os.listdir(data_source) ]\n",
    "print(f'len(files)={len(files)}')\n",
    "#         print(f'Total number of files: {len(files):,}')\n",
    "\n",
    "\n",
    "def unlabeled_from_data_source(data_source):\n",
    "    return [DataItem(name.split('.')[0]) for name in os.listdir(data_source)]\n",
    "\n",
    "unlabeled = [elem for list_ in list(map(unlabeled_from_data_source, data_sources)) for elem in list_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea08ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestion =[item for item in unlabeled if item.id_=='1136514515'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbf60b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7280"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33fdd286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['canada', 'year', 'new', ..., 'toronto city', 'multicultural',\n",
       "       'multiculturalism'], dtype='<U30')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d78ad7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['car', 'vehicle', 'automobile'], dtype='<U30')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[syn.vector()!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f552a6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01edc08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , ..., 0.        , 0.64985456,\n",
       "       0.76005859])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.data_item import QueryDataItem\n",
    "doc = QueryDataItem(\"multiculturalism multicultural\")\n",
    "doc.set_relevant()\n",
    "doc.vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "array([0.        , 0.        , 0.        , ..., 0.        , 0.70710678,\n",
    "       0.70710678])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffda106",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sources = ['/home/ec2-user/SageMaker/mariano/notebooks/07. Simulation/data/GM_files'\n",
    "               ]\n",
    "def unlabeled_from_data_source(data_source):\n",
    "    return [DataItem(name.split('.')[0]) for name in os.listdir(data_source)]\n",
    "unlabeled = [elem for list_ in list(map(unlabeled_from_data_source, data_sources)) for elem in list_]\n",
    "unlabeled = list(filter(lambda x: x.has_vector(), unlabeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed1ed455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "vectors=[]\n",
    "for vecname in [item._vector_filename() for item in unlabeled]:\n",
    "    vectors.append(pickle.load(open(vecname,'rb'))['BoW'].toarray()[0,:])\n",
    "    \n",
    "X = normalize(sparse.vstack(map(lambda filename: pickle.load(open(filename, 'rb'))['BoW']), vecnames[ini:fin])),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dce637f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18397 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "vecnames = [item._vector_filename() for item in unlabeled]\n",
    "sparse.vstack(map(lambda filename: pickle.load(open(filename, 'rb'))['BoW'], vecnames[0:100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5562f0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1124938409_representations.p\r\n",
      "1124939367_representations.p\r\n",
      "1124939834_representations.p\r\n",
      "1124940161_representations.p\r\n",
      "1124941625_representations.p\r\n",
      "1124942915_representations.p\r\n",
      "1124943522_representations.p\r\n",
      "1124945002_representations.p\r\n",
      "1124945205_representations.p\r\n",
      "1124945670_representations.p\r\n",
      "ls: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/ec2-user/SageMaker/mariano/notebooks/07.\\ Simulation/data/precomputed | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f5b4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1124938409.xml\r\n",
      "1124939367.xml\r\n",
      "1124939834.xml\r\n",
      "1124940161.xml\r\n",
      "1124941625.xml\r\n",
      "1124942915.xml\r\n",
      "1124943522.xml\r\n",
      "1124945002.xml\r\n",
      "1124945205.xml\r\n",
      "1124945670.xml\r\n",
      "ls: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/ec2-user/SageMaker/mariano/notebooks/07.\\ Simulation/data/GM_files | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1027033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmlfiles = ['data/GM_files/'+file for file in os.listdir('data/GM_files')]\n",
    "assert all([os.path.isfile(file) for file in xmlfiles])\n",
    "len(xmlfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4fd0294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecfiles = ['data/precomputed/'+file for file in os.listdir('data/precomputed/')]\n",
    "assert all([os.path.isfile(file) for file in vecfiles])\n",
    "len(vecfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed40e1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imm",
   "language": "python",
   "name": "imm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
