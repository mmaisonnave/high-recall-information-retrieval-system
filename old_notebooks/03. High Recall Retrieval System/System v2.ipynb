{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3918917f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-10 21:41:33.348775 [ \u001b[1;94mINFO\u001b[0m  ] Loading index...\n",
      "2022-02-10 21:41:36.147059 [ \u001b[1;94mINFO\u001b[0m  ] Index Loaded (192,427 files found).\n",
      "Enter Search Terms: dp OR displace\n",
      "2022-02-10 21:41:47.267877 [ \u001b[1;94mINFO\u001b[0m  ] Search completed, number of hits: 46,805.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a14b8cbfe44c879c638792ce60018e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3af6e9bbc64234a69cad5b8cab39f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Relevant', style=ButtonStyle()), Button(description='Irrelevâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a50280f5d940bca2151e6464e98bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-10 21:41:47.702138 [ \u001b[1;94mINFO\u001b[0m  ] Unlabeled data:           46,795\n",
      "2022-02-10 21:41:47.702247 [ \u001b[1;94mINFO\u001b[0m  ] Labeled data:                  0\n",
      "2022-02-10 21:41:47.702264 [ \u001b[1;94mINFO\u001b[0m  ] Just labeled:                 10\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "#                                    IMPORTS                                   #                                        \n",
    "################################################################################\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "from whoosh import index\n",
    "from whoosh.qparser import MultifieldParser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import spacy\n",
    "import myversions.pigeonXT as pixt\n",
    "from lxml import etree\n",
    "import pickle\n",
    "from sklearn.model_selection import cross_validate\n",
    "from IPython.core.display import display, HTML\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "# display(HTML('<h1>Hello, world!</h1>'))\n",
    "# from ipywidgets import Output\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import f1, precision, recall, accuracy\n",
    "################################################################################\n",
    "#                                       AUX                                    #                                        \n",
    "################################################################################\n",
    "\n",
    "def info(str_):\n",
    "    print(f'{datetime.datetime.now()} [ \\033[1;94mINFO\\x1b[0m  ] {str_}')\n",
    "def ok(str_):\n",
    "    print(f'{datetime.datetime.now()} [  \\033[1;92mOK\\x1b[0m   ] {str_}')\n",
    "def warning(str_):\n",
    "    print(f'{datetime.datetime.now()} [\\x1b[1;31mWARNING\\x1b[0m] {str_}')\n",
    "def html(str_=''):\n",
    "    display(HTML(str_))\n",
    "# info('Starting Script...')\n",
    "\n",
    "## ## ##\n",
    "\n",
    "################################################################################\n",
    "#                                   DataItem                                   #                                        \n",
    "################################################################################\n",
    "class DataItem(object):\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['tagger','parser','lemmatizer','textcat', 'ner'])\n",
    "    vocab = open('vocab/vocab_filtered.txt','r').read().splitlines()\n",
    "    word2idx = dict([(word,idx) for idx, word in enumerate(vocab)])\n",
    "    tokenizer = nlp.tokenizer\n",
    "    TS_data_path = '/home/ec2-user/SageMaker/data/Toronto_Star_Publication_with_query/'\n",
    "    GM_data_path = '/home/ec2-user/SageMaker/data/The_Globe_and_Mail_with_DP_filter_by_article_type/'\n",
    "    vectors_path = '/home/ec2-user/SageMaker/mariano/notebooks/03. High Recall Retrieval System/vectors/'\n",
    "    def __init__(self, file_id, source):\n",
    "        self.file_id = file_id\n",
    "        self.source = source\n",
    "        self.label = 'Undefined'\n",
    "        self.vector = None\n",
    "        self.bow_vector = None\n",
    "        self.prediction = None\n",
    "    def __eq__(self, other):\n",
    "        return self.file_id==other.file_id and self.source==other.source\n",
    "    def __str__(self):\n",
    "        return f'{self.file_id},{self.source}'\n",
    "    def filename(self):\n",
    "        if self.source=='Toronto Star':\n",
    "            return DataItem.TS_data_path+self.file_id\n",
    "        else:\n",
    "            return DataItem.GM_data_path+self.file_id\n",
    "    def vector(self):\n",
    "        if self.vector is None:\n",
    "            vector_filename = DataItem.vectors_path + self.file_id[:-4]+'.vector'\n",
    "            self.vector = pickle.load(open(vector_filename, 'rb'))\n",
    "        return self.vector\n",
    "    def get_bow_vector(self):\n",
    "        if self.bow_vector is None:\n",
    "            bow_vector_file = DataItem.vectors_path+self.file_id[:-4]+'.bow_vector'\n",
    "            if os.path.isfile(bow_vector_file):\n",
    "                self.bow_vector = pickle.load(open(bow_vector_file, 'rb'))\n",
    "            else:\n",
    "                self.bow_vector = np.zeros(shape=(len(DataItem.vocab)+1,))\n",
    "                if not text is None and not title is None:\n",
    "                    for token in DataItem.tokenizer(title+' '+text):\n",
    "                        t = token.text.replace('\\n','')\n",
    "                        t = t.lower()\n",
    "                        if t in DataItem.word2idx:\n",
    "                            self.bow_vector[DataItem.word2idx[t]]+=1\n",
    "                        else:\n",
    "                            self.bow_vector[len(DataItem.vocab)]+=1\n",
    "                    \n",
    "        return self.bow_vector\n",
    "    def _title_and_text(self):\n",
    "        tree = etree.parse(self.filename())\n",
    "        root = tree.getroot()\n",
    "        if root.find('.//HiddenText') is not None:\n",
    "            text = (root.find('.//HiddenText').text)\n",
    "\n",
    "        elif root.find('.//Text') is not None:\n",
    "            text = (root.find('.//Text').text)\n",
    "\n",
    "        else:\n",
    "            text = None\n",
    "        title = root.find('.//Title')\n",
    "        if title is not None:\n",
    "            title = title.text\n",
    "        if not text is None:\n",
    "            text = BeautifulSoup(text, parser='html.parser').get_text()\n",
    "        \n",
    "        return text,title\n",
    "    def get_docview_html(self, keywords=[]):\n",
    "        tree = etree.parse(self.filename())\n",
    "        root = tree.getroot()\n",
    "        if root.find('.//HiddenText') is not None:\n",
    "            text = (root.find('.//HiddenText').text)\n",
    "\n",
    "        elif root.find('.//Text') is not None:\n",
    "            text = (root.find('.//Text').text)\n",
    "\n",
    "        else:\n",
    "            text = None\n",
    "#         text = BeautifulSoup(text, parser='html.parser').get_text()\n",
    "#         text = re.sub('\\n\\n*', '<br>',text.strip())\n",
    "#         text = text.replace('\\n+','<br>')\n",
    "        title = root.find('.//Title').text\n",
    "        date = root.find('.//NumericDate').text\n",
    "        for keyword in keywords:\n",
    "            text = re.sub(f'({keyword})', f'<mark>\\\\1</mark>', text, flags=re.IGNORECASE)\n",
    "        # ADD DATE ########################\n",
    "        url = f'https://proquest.com/docview/{self.file_id[:-4]}'\n",
    "        url = f'<a href=\"{url}\">{url}</a>'\n",
    "        publisher = root.find('.//PublisherName').text\n",
    "        return  '<html><hr style=\\\"border-color:black\\\">'\\\n",
    "                '<u>TITLE</u>: &emsp;&emsp;{}<br>'\\\n",
    "                '<u>DATE</u>: &emsp;&emsp;{}<br>'\\\n",
    "                '<u>PUBLISHER</u>: &emsp;{}<br>'\\\n",
    "                '<u>URL</u>:&emsp;&emsp;&emsp;{}<hr>'\\\n",
    "                '{}<hr style=\\\"border-color:black\\\"></html>'.format(\n",
    "                                                                               str(title),\n",
    "                                                                               date,\n",
    "                                                                               publisher,\n",
    "                                                                               url,\n",
    "                                                                               str(text))\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                                    SYSTEM                                    #                                        \n",
    "################################################################################\n",
    "class HRSystem():\n",
    "\n",
    "    annotation_batch_size = 10\n",
    "    metric_names = ['fit_time', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1']\n",
    "    index_path = '/home/ec2-user/SageMaker/mariano/notebooks/03. High Recall Retrieval System/index'\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.iteration_no = 0\n",
    "        self.metrics = []\n",
    "        self.annotation_batch_size = 10\n",
    "        info('Loading index...')\n",
    "        self.ix = index.open_dir(HRSystem.index_path)\n",
    "        info(f'Index Loaded ({self.ix.doc_count():,} files found).')\n",
    "        \n",
    "\n",
    "\n",
    "    def _search(self,limit=10):\n",
    "        # Search query\n",
    "        query = input(\"Enter Search Terms: \")\n",
    "\n",
    "        mp = MultifieldParser(['title','body'],schema=self.ix.schema)\n",
    "        q = mp.parse(query) #mp.parse(u'Refugee and date:[19941112 TO 19941113]')\n",
    "\n",
    "        #OPEN\n",
    "        searcher = self.ix.searcher()\n",
    "        results = searcher.search(q, limit=limit)\n",
    "\n",
    "        aux_results = [(result['file_id'], result['source']) for result in results]\n",
    "        while len(aux_results)==0:\n",
    "            query = input(\"No hits found. Enter New Search Terms: \")\n",
    "            mp = MultifieldParser(['title','body'],schema=self.ix.schema)\n",
    "            q = mp.parse(query) #mp.parse(u'Refugee and date:[19941112 TO 19941113]')\n",
    "            results = searcher.search(q, limit=limit)\n",
    "            aux_results = [(result['file_id'], result['source']) for result in results]\n",
    "        searcher.close()\n",
    "        \n",
    "        self.query = query\n",
    "        return aux_results\n",
    "    \n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        self.for_labeling = []\n",
    "        results = self._search(limit=None)\n",
    "        info(f'Search completed, number of hits: {len(results):,}.')\n",
    "        for file_id,source in results[:min(len(results), self.annotation_batch_size)]:\n",
    "            self.for_labeling.append(DataItem(file_id, source))\n",
    "        \n",
    "        results = results[min(len(results), self.annotation_batch_size):]\n",
    "\n",
    "        self.annotations = pixt.annotate(\n",
    "            [data_item.get_docview_html(keywords=self.query.split(' ')) for data_item in self.for_labeling],\n",
    "            options = ['Relevant', 'Irrelevant'],\n",
    "            stop_at_last_example=False,\n",
    "            display_fn=html,\n",
    "        )\n",
    "\n",
    "        # Loading filenames\n",
    "    #     filenames = [TS_data_path+filename for filename in os.listdir(TS_data_path)]\n",
    "    #     filenames += [GM_data_path+filename for filename in os.listdir(GM_data_path)]\n",
    "    #     info(f'Files found in dataset: {len(filenames):8,}')\n",
    "\n",
    "\n",
    "        self.unlabeled_data = []\n",
    "        for file_id,source in results:\n",
    "            self.unlabeled_data.append(DataItem(file_id,source))\n",
    "    #     unlabeled_data = []\n",
    "    #     for filename in os.listdir(TS_data_path):\n",
    "    #         if not filename in for_labeling_set:\n",
    "    #             unlabeled_data.append(DataItem(filename, 'Toronto Star'))\n",
    "    #     for filename in os.listdir(GM_data_path):\n",
    "    #         if not filename in for_labeling_set:\n",
    "    #             unlabeled_data.append(DataItem(filename, 'The Globe and Mail'))\n",
    "\n",
    "        self.labeled_data = []\n",
    "    #     model = SVCx(kernel='rbf')\n",
    "        self.model = MultinomialNB()\n",
    "        info(f'Unlabeled data:         {len(self.unlabeled_data):8,}')\n",
    "        info(f'Labeled data:           {len(self.labeled_data):8}')\n",
    "        info(f'Just labeled:           {len(self.for_labeling):8}')\n",
    "#         return unlabeled_data, labeled_data, for_labeling, annotations, model\n",
    "\n",
    "    def loop(self):\n",
    "        self.iteration_no += 1\n",
    "        metrics = {}\n",
    "        self.metrics.append(metrics)\n",
    "#         self.metrics[self.iteration_no - 1] = metrics\n",
    "        \n",
    "        for item,label in zip(self.for_labeling, self.annotations['label']):\n",
    "            item.label=label\n",
    "            self.labeled_data.append(item)\n",
    "\n",
    "        self.for_labeling = []\n",
    "\n",
    "        # if there are no positive AND negative examples training is not performed (rely on search engine results)\n",
    "        if len(set([item.label for item in self.labeled_data]))==1:\n",
    "            if self.labeled_data[0].label==0:\n",
    "                warning('Positive examples missing to build a predictive model')\n",
    "            else:\n",
    "                warning('Negative examples missing to build a predictive model')\n",
    "            warning('Using results from search engine to retrieve examples for labeling...')\n",
    "            results = self._search(limit=None)\n",
    "            to_remove = set()\n",
    "            i = 0\n",
    "            # FROM RESULTS ADD TO for_labeling THE FIRST TEN IF NOT PRESENT IN labeled_data (already seen)\n",
    "            label_data_set = set([(item.file_id,item.source) for item in self.labeled_data])\n",
    "            unlabeled_data_set = set([(item.file_id, item.source) for item in self.unlabeled_data])\n",
    "\n",
    "            while len(self.for_labeling)!=self.annotation_batch_size and i < len(results):\n",
    "                file_id, source = results[i]\n",
    "                item_to_add = DataItem(file_id, source)\n",
    "                if not (file_id,source) in label_data_set:\n",
    "                    self.for_labeling.append(item_to_add)\n",
    "                    to_remove.add((item_to_add.file_id,item_to_add.source))\n",
    "                i+=1\n",
    "            # ADD NEW RESULTS TO UNLABELED (if not in labeled_data (already seen))\n",
    "            for file_id, source in results:\n",
    "                item = DataItem(file_id, source)\n",
    "                if not (file_id,source) in label_data_set and not (file_id,source) in unlabeled_data_set:\n",
    "                    self.unlabeled_data.append(item)\n",
    "\n",
    "            # REMOVING FROM UNLABELED EVERYTHING THAT WAS SET UP FOR BEING LABELED (in for_labeling)\n",
    "            i=0\n",
    "            while (i<len(self.unlabeled_data)):\n",
    "                if (self.unlabeled_data[i].file_id, self.unlabeled_data[i].source) in to_remove:\n",
    "                    del(self.unlabeled_data[i])\n",
    "                else:\n",
    "                    i+=1\n",
    "\n",
    "        else:   \n",
    "            info('Using predictive model to search example for labeling')\n",
    "            # Re training from labeled data\n",
    "            vectors = [item.get_bow_vector() for item in self.labeled_data]\n",
    "            X = np.vstack(vectors)\n",
    "            y = np.array([1 if item.label == 'Relevant' else 0 for item in self.labeled_data])\n",
    "            self.X=X\n",
    "            self.y=y\n",
    "            info('Training model on latest data...')\n",
    "            self.model.partial_fit(X,y, classes=[0,1])\n",
    "            \n",
    "            \n",
    "            # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "            #                                   STATUS                                    #\n",
    "            # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "            self.status()\n",
    "\n",
    "\n",
    "            #################################\n",
    "            ## THIS HAS TO BE DONE IN BATCHES\n",
    "            #################################\n",
    "            info('Computing predictions using newly trained model...')\n",
    "            batch_size = 20000\n",
    "            no_batches = int(1 + (len(self.unlabeled_data)/batch_size))\n",
    "            no_of_positives=0\n",
    "            for i in range(no_batches):\n",
    "#                 info(f'BATCH INFO: from {i*batch_size:8,} to {min(len(self.unlabeled_data),(i+1)*batch_size):8,}')\n",
    "                batch = self.unlabeled_data[i*batch_size:min(len(self.unlabeled_data),(i+1)*batch_size)]\n",
    "                X_batch = np.vstack([item.get_bow_vector() for item in batch])\n",
    "                yhat = self.model.predict(X_batch)\n",
    "                no_of_positives+= len([elem for elem in yhat if elem>0.5])\n",
    "                for item,prediction in zip(batch, yhat):\n",
    "                    item.prediction = prediction\n",
    "                    \n",
    "            info(f'Number of unlabeled instances predicted as \\'postive\\': {no_of_positives:,} ' )\n",
    "            metrics['remaining_positives'] = no_of_positives\n",
    "            \n",
    "            info('Sorting elements by relevance...')\n",
    "            yhat = [elem.prediction for elem in self.unlabeled_data]\n",
    "            args_to_remove = [arg for arg in np.argsort(yhat)[-10:]]\n",
    "            args_to_remove = sorted(args_to_remove, reverse=True)\n",
    "            for arg in args_to_remove:\n",
    "                self.for_labeling.append(self.unlabeled_data[arg])\n",
    "                del(self.unlabeled_data[arg])\n",
    "\n",
    "            del(X_batch)\n",
    "            del(yhat)\n",
    "        self.annotations = pixt.annotate(\n",
    "                                    [data_item.get_docview_html(keywords=self.query.split(' ')) for data_item in self.for_labeling],\n",
    "                                    options = ['Relevant', 'Irrelevant'],\n",
    "                                    stop_at_last_example=False,\n",
    "                                    display_fn=html,\n",
    "                                    )\n",
    "\n",
    "        info(f'Unlabeled data:         {len(self.unlabeled_data):8,}')\n",
    "        info(f'Labeled data:           {len(self.labeled_data):8}')\n",
    "        info(f'Just labeled:           {len(self.for_labeling):8}')    \n",
    "\n",
    "        \n",
    "    \n",
    "    def status(self):\n",
    "        metrics = self.metrics[self.iteration_no-1]\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        info('Model trained. Showing status of model...')\n",
    "        least_populated_class_count = min(len([elem for elem in y if elem==0]),len([elem for elem in y if elem==1]))\n",
    "        if least_populated_class_count>=3:\n",
    "            scores = cross_validate(MultinomialNB(),X,y,cv=3, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "            del(scores['score_time'])\n",
    "            for metric in scores:\n",
    "                metrics[metric] = scores[metric]\n",
    "                \n",
    "        else:\n",
    "            warning(f'Not computing scores due to lack of exmpales.')\n",
    "            warning(f'Least populated_class_count: {least_populated_class_count}')\n",
    "            warning(f'min({len([elem for elem in y if elem==0])},'\\\n",
    "                    f'{len([elem for elem in y if elem==1])})='\\\n",
    "                    f'{least_populated_class_count}')\n",
    "\n",
    "            for metric in HRSystem.metric_names:\n",
    "                metrics[metric] = None\n",
    "        metrics_df = pd.DataFrame(np.zeros(shape=(4,len(HRSystem.metric_names))) , \n",
    "                                      index=['fold 1', 'fold 2', 'fold 3', 'average'], \n",
    "                                      columns = HRSystem.metric_names \n",
    "                                     )\n",
    "        metrics_df.iloc[3,:] = np.average(metrics_df.iloc[:3,:],axis=0)\n",
    "        for column,metric in enumerate(metrics):\n",
    "            if metrics[metric] is None:\n",
    "                metrics_df.iloc[:,column]=np.nan\n",
    "            else:\n",
    "                for row,value in enumerate(metrics[metric]):\n",
    "                    metrics_df.iloc[row,column]=value\n",
    "        print(metrics_df)\n",
    "    def export(self):\n",
    "        pass\n",
    "system = HRSystem()\n",
    "system.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "700ef81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len([item for item in system.labeled_data if item.label=='Irrelevant']))\n",
    "print(len([item for item in system.labeled_data if item.label=='Relevant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1adaa2d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-10 21:33:52.955773 [ \u001b[1;94mINFO\u001b[0m  ] Using predictive model to search example for labeling\n",
      "2022-02-10 21:33:52.979175 [ \u001b[1;94mINFO\u001b[0m  ] Training model on latest data...\n",
      "2022-02-10 21:33:52.981436 [ \u001b[1;94mINFO\u001b[0m  ] Model trained. Showing status of model...\n",
      "2022-02-10 21:33:52.981543 [\u001b[1;31mWARNING\u001b[0m] Not computing scores due to lack of exmpales.\n",
      "2022-02-10 21:33:52.982121 [\u001b[1;31mWARNING\u001b[0m] Least populated_class_count: 2\n",
      "2022-02-10 21:33:52.982187 [\u001b[1;31mWARNING\u001b[0m] min(2,18)=2\n",
      "         fit_time  test_accuracy  test_precision  test_recall  test_f1\n",
      "fold 1        NaN            NaN             NaN          NaN      NaN\n",
      "fold 2        NaN            NaN             NaN          NaN      NaN\n",
      "fold 3        NaN            NaN             NaN          NaN      NaN\n",
      "average       NaN            NaN             NaN          NaN      NaN\n",
      "2022-02-10 21:33:53.002182 [ \u001b[1;94mINFO\u001b[0m  ] Computing predictions using newly trained model...\n",
      "2022-02-10 21:34:38.056813 [ \u001b[1;94mINFO\u001b[0m  ] Number of unlabeled instances predicted as 'postive': 46,597 \n",
      "2022-02-10 21:34:38.057042 [ \u001b[1;94mINFO\u001b[0m  ] Sorting elements by relevance...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f84c6918e4e4f238030c511baa92935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ce4ec381694dbaa05af2cd513863c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Relevant', style=ButtonStyle()), Button(description='Irrelevâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c13e33f1c6e43b09e5087b944e5f522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-10 21:34:38.213406 [ \u001b[1;94mINFO\u001b[0m  ] Unlabeled data:           46,587\n",
      "2022-02-10 21:34:38.213486 [ \u001b[1;94mINFO\u001b[0m  ] Labeled data:                 20\n",
      "2022-02-10 21:34:38.213521 [ \u001b[1;94mINFO\u001b[0m  ] Just labeled:                 10\n"
     ]
    }
   ],
   "source": [
    "system.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17a04977",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = system.X\n",
    "y = system.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9945426f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fit_time', 'score_time', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(MultinomialNB(),X,y,cv=3, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "scores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833c8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc7496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f171d9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-08 16:14:18.184120 [ INFO  ] Using predictive model to search example for labeling\n",
      "2022-02-08 16:14:18.278396 [ INFO  ] Score average: 0.750\n",
      "2022-02-08 16:14:18.278565 [ INFO  ] BATCH INFO: from        0 to   20,000\n",
      "2022-02-08 16:14:20.011948 [ INFO  ] BATCH INFO: from   20,000 to   40,000\n",
      "2022-02-08 16:14:21.202807 [ INFO  ] BATCH INFO: from   40,000 to   46,537\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af882b3ea3d24bbd90d7bdd3ac066f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7871f27577d1431e9f74895e4409067b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Relevant', style=ButtonStyle()), Button(description='Irrelevant', style=Butâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5654e55c312743d1a674e59a0a830499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-08 16:14:21.777174 [ INFO  ] Unlabeled data:           46,527\n",
      "2022-02-08 16:14:21.777237 [ INFO  ] Labeled data:                 80\n",
      "2022-02-08 16:14:21.777271 [ INFO  ] Just labeled:                 10\n",
      "Annotation done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "    \n",
    "unlabeled_data, labeled_data, for_labeling, annotations, model = loop(\n",
    "                                                                      unlabeled_data,\n",
    "                                                                      labeled_data, \n",
    "                                                                      for_labeling, \n",
    "                                                                      annotations, \n",
    "                                                                      model\n",
    "                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b9933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1949323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b13b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15161ead",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'for_labeling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6170/126556750.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfor_labeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbow_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'for_labeling' is not defined"
     ]
    }
   ],
   "source": [
    "for_l.bow_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "870d9cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2     True\n",
       "3     True\n",
       "4    False\n",
       "5     True\n",
       "6    False\n",
       "7     True\n",
       "8    False\n",
       "9     True\n",
       "Name: label, dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations['label']=='Relevant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8621192d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1140932582.xml', 'Relevant'),\n",
       " ('1444798819.xml', 'Relevant'),\n",
       " ('1412331290.xml', 'Relevant'),\n",
       " ('1237819981.xml', 'Relevant'),\n",
       " ('1400851797.xml', 'Relevant'),\n",
       " ('1151322272.xml', 'Relevant'),\n",
       " ('1237696430.xml', 'Relevant'),\n",
       " ('1444894211.xml', 'Relevant'),\n",
       " ('1146079007.xml', 'Relevant'),\n",
       " ('1151111154.xml', 'Relevant')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc9b49d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1140932582.xml'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_labeling['file_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc939bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a49a87921b41559289228ce221ee18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 2 Examples annotated.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ef62b839fd4e4d9b43986f965452a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='programming', style=ButtonStyle()), Button(description='not programming', sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb67a220d3c45e788d590f89cfbb1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>changed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;html&gt;Hello world&lt;br/&gt;&lt;/html&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello world2</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         example  changed label\n",
       "0  <html>Hello world<br/></html>    False      \n",
       "1                   Hello world2    False      "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation done.\n"
     ]
    }
   ],
   "source": [
    "import pigeonXT as pixt\n",
    "a = pixt.annotate(\n",
    "    [str('<html>Hello world<br/></html>'), 'Hello world2'],\n",
    "    options=['programming', 'not programming']\n",
    ")\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fbf2e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>changed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;html&gt;Hello world&lt;br/&gt;&lt;/html&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello world2</td>\n",
       "      <td>True</td>\n",
       "      <td>programming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         example  changed        label\n",
       "0  <html>Hello world<br/></html>     True  programming\n",
       "1                   Hello world2     True  programming"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "172fc60e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2598950515.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_27147/2598950515.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    jupyter lab\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c69639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imm",
   "language": "python",
   "name": "imm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
