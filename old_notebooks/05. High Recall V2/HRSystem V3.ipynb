{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afeead2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘cache/models.joblib’: No such file or directory\n",
      "rm: cannot remove ‘cache/highlighter.joblib’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm cache/models.joblib\n",
    "!rm cache/highlighter.joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a2667ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000009"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vec = system.labeled_data[0].vector() / np.linalg.norm(system.labeled_data[0].vector())\n",
    "np.linalg.norm(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "912563ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 19:14:01.789046 [  \u001b[1;92mOK\u001b[0m   ] Done\n"
     ]
    }
   ],
   "source": [
    "from utils.tdmstudio import TDMStudio\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from utils.models import tokenize\n",
    "import spacy\n",
    "from joblib import dump, load\n",
    "from utils.general import info, ok\n",
    "nlp = spacy.load('en_core_web_sm', disable=['textcat', 'parser','ner'])\n",
    "from utils.models import DataItem\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "invalid = set([sw for sw in stopwords if any([token for token in tokenize(sw) if not token in stopwords ])]) # ['‘ve', \"'m\", '’ve', \"'ve\", '’m', '‘m', '‘d', '‘ll']\n",
    "stopwords = set(stopwords.difference(invalid)) \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TermHighlighter(object):\n",
    "    def __init__(self):\n",
    "        self.no_to_highlight=10\n",
    "        self.model = LogisticRegression(C=1)\n",
    "        self.trained = False\n",
    "        self.rng = np.random.default_rng(2022)\n",
    "        self.nlp = spacy.load('en_core_web_sm', disable=['textcat', 'parser','ner'])\n",
    "\n",
    "        self.vocab=np.array(open('../04. Model of DP/precomputed/vocab_with_dp.txt', 'r').read().splitlines())\n",
    "    def fit(self, item_list, balance_data=False):\n",
    "        assert all([item.label!=DataItem.UNK_LABEL for item in item_list])\n",
    "        \n",
    "        if balance_data:\n",
    "            rel_list = [item for item in item_list if item.label==DataItem.REL_LABEL]\n",
    "            norel_args = [ix for ix,item in enumerate(item_list) if item.label==DataItem.IREL_LABEL]\n",
    "            selected_args = self.rng.choice(norel_args, size=len(rel_list), replace=False)\n",
    "            item_list = [item_list[arg] for arg in selected_args] + rel_list\n",
    "            self.rng.shuffle(item_list)\n",
    "            \n",
    "\n",
    "        \n",
    "        X = DataItem.get_X(item_list, type_=DataItem.TYPE_BOW)\n",
    "        y = DataItem.get_y(item_list)\n",
    "        \n",
    "        self.model.fit(X,y)\n",
    "        \n",
    "        term_score = [(term,coef) for term,coef in zip(self.vocab, self.model.coef_[0,:])]\n",
    "        term_score = sorted(term_score , key=lambda x:x[1],reverse=True)\n",
    "        term_score = term_score[:20]\n",
    "        self.term2coef = dict(term_score)\n",
    "        self.trained=True\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'<TermHighlighter model={self.model} trained={self.trained} vocab=<{self.vocab[0]}, ..., {self.vocab[1]}>>'\n",
    "    def predict(self,item_list):\n",
    "        assert self.trained\n",
    "        \n",
    "        X = DataItem.get_X(item_list, type_=DataItem.TYPE_BOW)\n",
    "        return self.model.predict_proba(X)[:,1]\n",
    "    \n",
    "    def highlight(self, text):\n",
    "        \n",
    "        doc = self.nlp(text)\n",
    "        tokens = np.array([token for token in doc if token.lemma_.lower() in self.term2coef])\n",
    "        scores = np.array([self.term2coef[token.lemma_.lower()] for token in tokens])\n",
    "        \n",
    "        tokens = tokens[np.argsort(scores)][::-1]\n",
    "        index_pairs = []\n",
    "        visited=set()\n",
    "        idx=0\n",
    "        while len(visited)<self.no_to_highlight and  idx<len(tokens):\n",
    "            index_pairs.append((tokens[idx].idx,tokens[idx].idx+len(tokens[idx].text),))\n",
    "            visited.add(tokens[idx].lemma_.lower())\n",
    "            idx+=1\n",
    "            \n",
    "        return TermHighlighter._highlight(text, index_pairs)\n",
    "    \n",
    "    def _highlight(text, index_pairs):\n",
    "        index_pairs = sorted(index_pairs, key=lambda x:x[0], reverse=True)\n",
    "        for ini,fin in index_pairs:\n",
    "            len_ = fin-ini\n",
    "            text = text[:ini] +'<mark style=\"background-color:red\">'+text[ini:fin]+'</mark>' +text[ini+len_:]\n",
    "        return text\n",
    "    \n",
    "    def sorted_terms(self):\n",
    "        assert self.trained\n",
    "        \n",
    "        return list(reversed((self.vocab[np.argsort(np.abs(self.model.coef_))])[0,:]))\n",
    "\n",
    "# labl_data=[]\n",
    "# #############################\n",
    "# # LABELED OVER THREE ROUNDS #\n",
    "# #############################\n",
    "# for line in open('labeled_data.csv').read().splitlines()[1:]:\n",
    "#     id_,label = line.split(';')\n",
    "#     item = DataItem(id_)\n",
    "#     if label=='R':\n",
    "#         item.set_relevant()\n",
    "#     else:\n",
    "#         item.set_irrelevant()\n",
    "#         assert label=='I'\n",
    "#     if item.has_vector():\n",
    "#         labl_data.append(item)\n",
    "        \n",
    "# term_highlighter = TermHighlighter() \n",
    "# term_highlighter.fit(labl_data)\n",
    "# print('done!')\n",
    "ok('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d91418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 19:14:01.797941 [  \u001b[1;92mOK\u001b[0m   ] Done\n"
     ]
    }
   ],
   "source": [
    "from utils.models import DataItem\n",
    "\n",
    "class Classifier(object):\n",
    "    \n",
    "    def __init__(self, model, type_=DataItem.TYPE_BOW):\n",
    "        self.model = model\n",
    "        self.vector_type = type_\n",
    "        self.trained=False\n",
    "        self.rng = np.random.default_rng(2022)\n",
    "        \n",
    "    def _fit(self, item_list, partial=False):\n",
    "        assert all([item.label!=DataItem.UNK_LABEL for item in item_list])\n",
    "\n",
    "            \n",
    "        X = DataItem.get_X(item_list, type_=self.vector_type)\n",
    "        y = DataItem.get_y(item_list)\n",
    "        if not partial:\n",
    "            self.model.fit(X,y)\n",
    "        else:\n",
    "            self.model.partial_fit(X,y)\n",
    "        self.trained=True\n",
    "        \n",
    "    def fit(self,item_list):\n",
    "        self._fit(item_list,partial=False)\n",
    "    \n",
    "    def partial_fit(self, item_list):\n",
    "        self._fit(item_list,partial=True)\n",
    "        \n",
    "    def predict(self,item_list):\n",
    "        assert self.trained\n",
    "        \n",
    "        X = DataItem.get_X(item_list, type_=self.vector_type)\n",
    "        \n",
    "        return self.model.predict_proba(X)[:,1]\n",
    "    def __str__(self):\n",
    "        return f'<Clasifier vec_type={self.vector_type} trained={self.trained} model={str(self.model)}>'\n",
    "ok('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3a8d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 19:14:02.724513 [  \u001b[1;92mOK\u001b[0m   ] Done\n"
     ]
    }
   ],
   "source": [
    "from utils.general import info, ok, warning, html\n",
    "import os\n",
    "from utils.models import DataItem\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import myversions.pigeonXT as pixt\n",
    "import pickle\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from math import ceil\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.models import tokenize\n",
    "import spacy\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "class HRSystem(object):\n",
    "#     UNLABELDATA_PATH = 'unlabeled_data.p'\n",
    "#     LABELDATA_PATH = 'labeled_data.p'\n",
    "    EXPANSION=10\n",
    "    LABELING_BATCH=10\n",
    "    LABELING_THRESHOLD=0.90\n",
    "    RELEVANT_LABEL='Relevant'\n",
    "    IRRELEVANT_LABEL='Irrelevant'\n",
    "    CACHE_PATH='./cache/'\n",
    "    LABELED_PATH=CACHE_PATH+'labeled_data_not_incanada.p'       ## <<< MODIFIED\n",
    "    UNLABELED_PATH=CACHE_PATH+'unlabeled_data.p'   ## <<< MODIFIED\n",
    "    VECTOR_TYPE=DataItem.TYPE_BOW\n",
    "    VOCAB = np.array(open('../04. Model of DP/precomputed/vocab_with_dp.txt').read().splitlines())\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['textcat', 'parser','ner'])\n",
    "    MODELS_FILE = 'cache/models.joblib'\n",
    "    HIGHLIGHTHER_FILE = 'cache/highlighter.joblib'\n",
    "    \n",
    "    def __init__(self,from_scratch=False):\n",
    "        self.estimated_remaining_relevant=None\n",
    "        self.rangen = np.random.default_rng(2022)\n",
    "        self.suggestions=[]\n",
    "        self.annotations = pd.DataFrame([],columns=['label'])\n",
    "        \n",
    "        ################\n",
    "        # LABELED DATA #\n",
    "        ################\n",
    "        if not from_scratch:\n",
    "            if not os.path.isfile(HRSystem.LABELED_PATH):\n",
    "                warning('Computing labeled data')\n",
    "                #########################\n",
    "                # NOT MENTIONING CANADA #\n",
    "                #########################\n",
    "#                 IN_CANADA_FILE = './auxiliary_notebooks/in_canada.csv'\n",
    "#                 lines = open(IN_CANADA_FILE,'r').read().splitlines()\n",
    "#                 irrelevant_ids = set([line.split(';')[0] for line in lines if line.endswith('False')])\n",
    "#                 self.labeled_data = [DataItem(id_) for id_ in irrelevant_ids]\n",
    "#                 for item in self.labeled_data:\n",
    "#                     item.set_irrelevant()\n",
    "                self.labeled_data=[]\n",
    "                #############################\n",
    "                # LABELED OVER THREE ROUNDS #\n",
    "                #############################\n",
    "                for line in open('labeled_data.csv').read().splitlines()[1:]:\n",
    "                    id_,label = line.split(';')\n",
    "                    item = DataItem(id_)\n",
    "                    if label=='R':\n",
    "                        item.set_relevant()\n",
    "                    else:\n",
    "                        item.set_irrelevant()\n",
    "                        assert label=='I'\n",
    "                    if item.has_vector():\n",
    "                        self.labeled_data.append(item)\n",
    "                \n",
    "\n",
    "            else:\n",
    "                #############################################\n",
    "                # RETRIEVING FROM DISK INSTEAD OF COMPUTING #\n",
    "                #############################################\n",
    "                info('Retrieving labeled data from disk')\n",
    "                self.labeled_data = pickle.load(open(HRSystem.LABELED_PATH,'rb'))\n",
    "            \n",
    "\n",
    "        ##################\n",
    "        # UNLABELED DATA #\n",
    "        ##################\n",
    "        GM1 = '/home/ec2-user/SageMaker/data/GM_all_1945_1956/'\n",
    "        GM2 = '/home/ec2-user/SageMaker/data/GM_all_1957-1967/'\n",
    "        if not os.path.isfile(HRSystem.UNLABELED_PATH):\n",
    "            warning('Computing unlabeled data')\n",
    "            self.unlabeled_data = [DataItem(GM1+file_) for file_ in os.listdir(GM1)] + [DataItem(GM2+file_) for file_ in os.listdir(GM2)]\n",
    "            relevant_ids = set([item.id_ for item in self.labeled_data])\n",
    "            self.unlabeled_data = [item for item in self.unlabeled_data if item.has_vector() and not item.id_ in relevant_ids]\n",
    "            \n",
    "        else:\n",
    "            #############################################\n",
    "            # RETRIEVING FROM DISK INSTEAD OF COMPUTING #\n",
    "            #############################################\n",
    "            info('Retrieving unlabeled data from disk')\n",
    "            self.unlabeled_data = pickle.load(open(HRSystem.UNLABELED_PATH,'rb'))\n",
    "            \n",
    "        \n",
    "        self.rangen.shuffle(self.unlabeled_data)\n",
    "        self.unlabeled_data = self.unlabeled_data\n",
    "        \n",
    "        if from_scratch:\n",
    "            self.labeled_data=[]\n",
    "            valid=False\n",
    "            while not valid:\n",
    "                seed = input('Please insert URLs to relevant document (; sep) (e.g., https://www.proquest.com/docview/1288605023/...)')\n",
    "                matches = re.findall('docview/([0-9]*)/',seed)\n",
    "                if len(matches)>=1:\n",
    "                    ids = set(matches)\n",
    "                    print(ids)\n",
    "                    positions = [idx for idx,item in enumerate(self.unlabeled_data) if item.id_ in ids]\n",
    "                    if len(positions)>=1:\n",
    "                        for position in reversed(positions):\n",
    "                            self.labeled_data.append(self.unlabeled_data[position])\n",
    "                            self.labeled_data[-1].set_relevant()\n",
    "                            del(self.unlabeled_data[position])\n",
    "                        valid=True\n",
    "                    else:\n",
    "                        warning('Documents not found in database (The Globe and Mail 1936 onwards), please try again.')\n",
    "                else:\n",
    "                    warning('Invalid URLs, please try again.')\n",
    "                  \n",
    "        ################################\n",
    "        # PRELOAD LABELED DATA VECTORS #\n",
    "        ################################\n",
    "        for item in self.labeled_data:\n",
    "            item.preload_vector(type_=DataItem.TYPE_GLOVE300)\n",
    "            item.preload_vector(type_=DataItem.TYPE_GLOVE600)\n",
    "       \n",
    "        info(f'Number of unlabeled documents: {len(self.unlabeled_data):10,}')\n",
    "        info(f'Number of labeled documents:   {len(self.labeled_data):10,}')\n",
    "        \n",
    "        \n",
    "        if not os.path.isfile(HRSystem.MODELS_FILE):\n",
    "            warning('Creating the model from scratch.')\n",
    "            assert not os.path.isfile(HRSystem.HIGHLIGHTHER_FILE)\n",
    "            self.classifiers = [Classifier(MLPClassifier(early_stopping=False,max_iter=1500,hidden_layer_sizes=(20,), solver='adam'), type_=DataItem.TYPE_BOW),\n",
    "                                Classifier(MLPClassifier(early_stopping=False,max_iter=1500,hidden_layer_sizes=(100,), solver='adam'), type_=DataItem.TYPE_GLOVE300),\n",
    "    #                        Classifier(SVC(kernel='linear', C=1, probability=True), type_=DataItem.TYPE_BOW),\n",
    "    #                        Classifier(SVC(kernel='rbf', C=7, probability=True), type_=DataItem.TYPE_GLOVE300),\n",
    "    #                        Classifier(SVC(kernel='poly', C=1, degree=3 ,probability=True), type_=DataItem.TYPE_GLOVE600),\n",
    "    #                        Classifier(LogisticRegression(), type_=DataItem.TYPE_GLOVE600),\n",
    "                          ]\n",
    "\n",
    "            self.term_highlighter = TermHighlighter()\n",
    "            info('Training model')\n",
    "\n",
    "\n",
    "            self._retrain(partial=False)\n",
    "            \n",
    "#             self._save_models()\n",
    "        else:\n",
    "            info('Loading models from disk')\n",
    "            assert os.path.isfile(HRSystem.HIGHLIGHTHER_FILE)\n",
    "            self._load_models()\n",
    "\n",
    "        self.status()\n",
    "     \n",
    "    def _save_models(self):\n",
    "        if os.path.isfile(HRSystem.MODELS_FILE):\n",
    "            warning('Overwriting models with new version.')\n",
    "        dump(self.classifiers, HRSystem.MODELS_FILE)\n",
    "        dump(self.term_highlighter, HRSystem.HIGHLIGHTHER_FILE)\n",
    "    def _load_models(self):\n",
    "        self.term_highlighter = load(HRSystem.HIGHLIGHTHER_FILE)\n",
    "        self.classifiers = load(HRSystem.MODELS_FILE)\n",
    "        \n",
    "    def _retrain(self, partial=True): \n",
    "        expanded=False\n",
    "        if len(self.labeled_data)<10:\n",
    "            warning('Expanding labeled data')\n",
    "            expanded=True            \n",
    "            self.labeled_data += [DataItem(item.id_) for item in self.rangen.choice(\n",
    "                                                                                   self.unlabeled_data,\n",
    "                                                                                   size=HRSystem.EXPANSION,\n",
    "                                                                                   replace=False)]\n",
    "            for item in self.labeled_data[-HRSystem.EXPANSION:]:\n",
    "                item.set_irrelevant()\n",
    "        \n",
    "        for clf in self.classifiers:\n",
    "            info(f'Training: {str(clf)}')\n",
    "            if not partial:\n",
    "                clf.fit(self.labeled_data)\n",
    "            else:\n",
    "                clf.partial_fit(self.labeled_data[-HRSystem.LABELING_BATCH:])\n",
    "            \n",
    "        info('training term highlighter')\n",
    "        self.term_highlighter.fit(self.labeled_data)\n",
    "        ok('done')\n",
    "                     \n",
    "#         X = DataItem.get_X(self.labeled_data, type_=HRSystem.VECTOR_TYPE)\n",
    "#         y = DataItem.get_y(self.labeled_data)\n",
    "        \n",
    "#         #############\n",
    "#         # BALANCING #\n",
    "#         #############\n",
    "#         if not expanded:\n",
    "#             no_rel = np.sum(y==1)\n",
    "#             no_irrel = np.sum(y==0)\n",
    "#             args = self.rangen.choice(range(no_irrel),size=no_rel, replace=False)\n",
    "#             X_bal = np.zeros(shape=(no_rel*2,X.shape[1]), dtype='int32')\n",
    "\n",
    "#             X_bal[:no_rel,:] = X[y==1,:]\n",
    "#             X_bal[no_rel:,:] = X[y==0,:][args,:]\n",
    "#             y_bal = np.zeros(shape=(no_rel*2,), dtype='int32')\n",
    "#             y_bal[:no_rel]=1\n",
    "\n",
    "#             X = X_bal\n",
    "#             y = y_bal        \n",
    "#         #############\n",
    "        \n",
    "        if expanded:\n",
    "                self.labeled_data = self.labeled_data[:-HRSystem.EXPANSION]\n",
    "        \n",
    "#                                      #################\n",
    "#         if self._relevant_count()>5: ## GRID SEARCH ##\n",
    "#                                      #################\n",
    "                \n",
    "#             params = {'C':[0.1,  1, 5, 15, 50,  500]}\n",
    "            \n",
    "# #             if X.shape[0]>5000:\n",
    "# #                 args = self.rangen.choice(range(X.shape[0]),size=5000, replace=False)\n",
    "# #                 X_red = X[args ,:]\n",
    "# #                 y_red = y[args]\n",
    "            \n",
    "#             GS = GridSearchCV(\n",
    "#                               LogisticRegression(),                          ## CHANGE FOR BOW\n",
    "#                               params\n",
    "#                               ,scoring=['f1','accuracy','precision', 'recall'], \n",
    "#                               cv=5,\n",
    "#                               verbose=1, \n",
    "#                               refit='f1')    \n",
    "\n",
    "            \n",
    "            \n",
    "#             with warnings.catch_warnings():\n",
    "#                 warnings.simplefilter(\"ignore\")\n",
    "#                 rta = GS.fit(X,y)\n",
    "\n",
    "#             df = (pd.DataFrame(rta.cv_results_)[[\"params\",\"mean_test_accuracy\", \"mean_test_precision\",\"mean_test_recall\",\"mean_test_f1\"]])\n",
    "#             df.columns=['params','mean accuracy', 'mean precision','mean recall','mean f1',]\n",
    "#             print(df)\n",
    "#             info(f'Best Params{rta.best_params_}')\n",
    "#             C = rta.best_params_['C']\n",
    "# #             self.bgg_clf = BaggingClassifier()\n",
    "# #             self.logreg_clf = LogisticRegression( C=rta.best_params_['C'])\n",
    "#         else:\n",
    "#             C=100\n",
    "#             warning('Unable to compute Grid Search')\n",
    "#             self.clf = LogisticRegression( C=100)\n",
    "\n",
    "#         self.bgg_clf = BaggingClassifier(\n",
    "#                                          base_estimator=LogisticRegression(C=C),\n",
    "#                                          n_estimators=5,\n",
    "#                                          max_samples=0.25,\n",
    "#                                          max_features=1\n",
    "#                                         )\n",
    "#         self.logreg_clf = LogisticRegression(C=C)        \n",
    "# #         self.bgg_clf.fit(X,y)       \n",
    "#         self.logreg_clf.fit(X,y)\n",
    "#         print(f'finished training model: {str(self.logreg_clf)}')\n",
    "#         del(X,y)\n",
    "    \n",
    "    def status(self):\n",
    "#         labels = ['labeled', 'remaining relevant', ]\n",
    "        value1 = len(self.labeled_data)/( len(self.labeled_data)+len(self.unlabeled_data))\n",
    "        length=75\n",
    "        \n",
    "        cant = ceil(value1*length)\n",
    "        print('|'+ '█'*cant + '-'*(length-cant)+'|'+f'{value1*100:6.2f}% labeled')\n",
    "        \n",
    "        if not self.estimated_remaining_relevant is None :\n",
    "            value2 = self.estimated_remaining_relevant/len(self.unlabeled_data)\n",
    "            second_length = length-cant\n",
    "            second_cant= ceil(value2*second_length)\n",
    "            print(' '*cant +'|' + '█'*(second_cant)+'-'*(second_length-second_cant)+ '|'+f'{value2*100:6.2f}% remaining '\\\n",
    "                                                                                                        'relevant (estimated)')        \n",
    "    def save(self):\n",
    "        pickle.dump(self.labeled_data, open(HRSystem.LABELED_PATH, 'wb'))\n",
    "        pickle.dump(self.unlabeled_data, open(HRSystem.UNLABELED_PATH, 'wb'))\n",
    "        self._save_models()\n",
    "    \n",
    "    def _relevant_count(self):\n",
    "        return len([item for item in self.labeled_data if item.label==DataItem.REL_LABEL])\n",
    "        \n",
    "    def _labeled_count(self):\n",
    "        return len(self.labeled_data)\n",
    "    def _unlabeled_count(self):\n",
    "        return len(self.unlabeled_data)\n",
    "    def loop(self, batch_size=10):        \n",
    "        ####################################################\n",
    "        # MOVING FROM SUGGESTIONS (ANNOTATIONS) TO LABELED #\n",
    "        ####################################################\n",
    "        need_retrain=False\n",
    "        if len(self.suggestions)>0:\n",
    "            info(f'Moving {len(self.suggestions)} annotated suggestions' \\\n",
    "            f' to labeled data ({len(self.labeled_data)} + {len(self.suggestions)})')\n",
    "            need_retrain=True\n",
    "            \n",
    "        for item,label in zip(self.suggestions, self.annotations[\"label\"]):\n",
    "            if label==HRSystem.RELEVANT_LABEL:\n",
    "                item.set_relevant()\n",
    "            else:\n",
    "                item.set_irrelevant()\n",
    "                assert label==HRSystem.IRRELEVANT_LABEL\n",
    "                \n",
    "        self.labeled_data = self.labeled_data+self.suggestions\n",
    "        del(self.annotations)\n",
    "    \n",
    "        if need_retrain:\n",
    "            info('Re-training...')\n",
    "            self._retrain()\n",
    "#             self._save_models()\n",
    "\n",
    "        ##########\n",
    "        ## HERE ##\n",
    "        ##########\n",
    "        cap = 50000\n",
    "        info('Re-trained. Computing suggestions...')\n",
    "        \n",
    "        candidate_args = self.rangen.choice(range(len(self.unlabeled_data)), size=cap, replace=False )\n",
    "        info(f'Making predictions over {len(candidate_args)} with model: {self.classifiers[0]}')\n",
    "        yhat1 = self.classifiers[0].predict([self.unlabeled_data[arg] for arg in candidate_args])\n",
    "        print(f'yhat1.shape={yhat1.shape}')\n",
    "        plt.hist(yhat1, bins=30)\n",
    "        plt.show()\n",
    "        \n",
    "        info(f'Descarding {len(candidate_args)-np.sum(yhat1>0.5)} articles.')\n",
    "        candidate_args = np.array(candidate_args)[yhat1>0.5]\n",
    "        yhat1 = yhat1[yhat1>0.5]\n",
    "        \n",
    "        info(f'Making predictions over {len(candidate_args)} with model: {self.classifiers[1]}')\n",
    "        yhat2 = self.classifiers[1].predict([self.unlabeled_data[arg] for arg in candidate_args])\n",
    "#         yhat3 = self.classifiers[2].predict([self.unlabeled_data[arg] for arg in candidate_args])\n",
    "        \n",
    "        \n",
    "        info(f'Descarding {len(candidate_args)-np.sum(yhat2>0.5)} articles.')\n",
    "        mask = (yhat2>0.5) #& (yhat3>0.5)\n",
    "        \n",
    "        yhat1 = yhat1[mask]\n",
    "        yhat2 = yhat2[mask]\n",
    "#         yhat3 = yhat3[mask]\n",
    "        print(f'yhat1.shape={yhat1.shape}')\n",
    "        print(f'yhat2.shape={yhat2.shape}')\n",
    "#         print(f'yhat3.shape={yhat3.shape}')\n",
    "        candidate_args = np.array(candidate_args)[mask]\n",
    "        \n",
    "        \n",
    "        info(f'Making predictions over {len(candidate_args)} with model: {self.term_highlighter}')\n",
    "        yhat4 = self.term_highlighter.predict([self.unlabeled_data[arg] for arg in candidate_args])\n",
    "        \n",
    "        print(f'yhat4.shape={yhat4.shape}')\n",
    "        yhat = np.average(np.vstack([yhat1,yhat2,yhat4]), axis=0)\n",
    "#         yhat = np.average(np.vstack([yhat1,yhat2,yhat4]), axis=0)\n",
    "        \n",
    "        candidate_args = np.array(candidate_args)[np.argsort(yhat)[::-1]]\n",
    "        \n",
    "#         yhat = np.zeros(shape=(len(self.unlabeled_data)))\n",
    "#         batch=5000\n",
    "#         end = len(self.unlabeled_data)\n",
    "#         self.rangen.shuffle(self.unlabeled_data)\n",
    "#         estimated=False\n",
    "#         for i in range(0,end,batch):\n",
    "#             f = min(i+batch,end)\n",
    "#             X = DataItem.get_X(self.unlabeled_data[i:f], type_=HRSystem.VECTOR_TYPE)\n",
    "#             yhat[i:f] = self.logreg_clf.predict_proba(X)[:,1]\n",
    "#             if (np.sum(yhat > HRSystem.LABELING_THRESHOLD)>HRSystem.LABELING_BATCH):\n",
    "#                 estimated=True\n",
    "#                 break\n",
    "                \n",
    "                \n",
    "#         no_of_processed = f\n",
    "        estimated=True\n",
    "\n",
    "\n",
    "        no_of_relevants_found = np.sum(yhat>0.5)\n",
    "        \n",
    "        estimated_relevants = int((no_of_relevants_found/cap)*len(self.unlabeled_data))\n",
    "        self.estimated_remaining_relevant = estimated_relevants\n",
    "        str_ = f'Number of relevant articles found: {estimated_relevants}'\n",
    "        \n",
    "        str_ += ' (ESTIMATED)' if estimated else ' (FINAL)'\n",
    "        info(str_)\n",
    "        # Remove most promising from unlabeled \n",
    "        #   and add to suggestions\n",
    "        \n",
    "        ################\n",
    "        ## UNTIL HERE ##\n",
    "        ################\n",
    "        \n",
    "        self.suggestions = []\n",
    "        self.annotations = []\n",
    "        \n",
    "        if no_of_relevants_found==0:\n",
    "            warning('There are no good candidates provided by the model. '\\\n",
    "            'This could happend at the beginin and at the end of the labeling process')\n",
    "            \n",
    "        end = min(len(candidate_args),batch_size)\n",
    "        best_ten_args = candidate_args[:end]\n",
    "        \n",
    "#         best_ten_args = np.argsort(yhat)[-start:][::-1]\n",
    "\n",
    "        for arg in best_ten_args:\n",
    "            self.suggestions.append(self.unlabeled_data[arg])\n",
    "\n",
    "        for arg in sorted(best_ten_args,reverse=True):\n",
    "            del(self.unlabeled_data[arg])\n",
    "\n",
    "\n",
    "        for item in self.suggestions:\n",
    "            item.preload_vector(type_=HRSystem.VECTOR_TYPE)\n",
    "\n",
    "\n",
    "        info(f'Moving {len(self.suggestions)} unlabeled suggestions'\\\n",
    "             f' from unlabeled data ({len(self.unlabeled_data)} - {len(self.suggestions)})')\n",
    "        \n",
    "        highlighter = None\n",
    "        if self.term_highlighter.trained:\n",
    "            highlighter = self.term_highlighter\n",
    "        text_for_label = [suggestion.get_htmldocview(highlighter=highlighter)\n",
    "                          for suggestion in self.suggestions]\n",
    "#         sorted_keyterms = self.term_highlighter.sorted_terms()\n",
    "        \n",
    "        \n",
    "#         for i, text in enumerate(text_for_label):\n",
    "#             ltext = text.lower()\n",
    "#             ix=0\n",
    "#             encontre=0\n",
    "#             while encontre<20 and ix<len(sorted_keyterms):\n",
    "#                 if sorted_keyterms[ix] in ltext:\n",
    "#                     #HIGHLIGHT\n",
    "#                     text_for_label[i] = re.sub(\n",
    "#                                                f'([^\\<\\>\\w\\S])({sorted_keyterms[ix]})([^\\<\\>\\w\\S])', \n",
    "#                                                f'\\\\1<mark style=\"background-color:red\">\\\\2</mark>\\\\3', \n",
    "#                                                text_for_label[i], \n",
    "#                                                flags=re.IGNORECASE)\n",
    "#                     encontre+=1\n",
    "#                 ix+=1\n",
    "\n",
    "        self.status()\n",
    "        self.annotations = pixt.annotate(\n",
    "                                         text_for_label,\n",
    "                                         options=[HRSystem.RELEVANT_LABEL, HRSystem.IRRELEVANT_LABEL],\n",
    "                                         stop_at_last_example=False,\n",
    "                                         display_fn=html,\n",
    "                                        )\n",
    "\n",
    "    def _get_htmldocview(text):\n",
    "        \n",
    "        pass\n",
    "    def export(self):\n",
    "        # 1. export CSV with IDs and URLs\n",
    "        pass\n",
    "\n",
    "    \n",
    "ok('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     LABELED_PATH=CACHE_PATH+'labeled_data_not_incanada.p'       ## <<< MODIFIED\n",
    "#     UNLABELED_PATH=CACHE_PATH+'unlabeled_data.p'   ## <<< MODIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mv cache/labeled_data_not_incanada.p cache/labeled_data_not_incanada.p.bak\n",
    "# !mv cache/unlabeled_data.p cache/unlabeled_data.p.bak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07e405f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# system.term_highlighter = TermHighlighter()\n",
    "# system.term_highlighter.fit(system.labeled_data)\n",
    "# dump(system.term_highlighter, HRSystem.HIGHLIGHTHER_FILE)\n",
    "# system.term_highlighter.sorted_terms()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "289474d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 19:14:05.363673 [ \u001b[1;94mINFO\u001b[0m  ] Retrieving labeled data from disk\n",
      "2022-04-13 19:14:05.508109 [ \u001b[1;94mINFO\u001b[0m  ] Retrieving unlabeled data from disk\n",
      "2022-04-13 19:14:16.963381 [ \u001b[1;94mINFO\u001b[0m  ] Number of unlabeled documents:  2,042,223\n",
      "2022-04-13 19:14:16.963499 [ \u001b[1;94mINFO\u001b[0m  ] Number of labeled documents:        7,178\n",
      "2022-04-13 19:14:16.963560 [\u001b[1;31mWARNING\u001b[0m] Creating the model from scratch.\n",
      "2022-04-13 19:14:17.409848 [ \u001b[1;94mINFO\u001b[0m  ] Training model\n",
      "2022-04-13 19:14:17.410426 [ \u001b[1;94mINFO\u001b[0m  ] Training: <Clasifier vec_type=B trained=False model=MLPClassifier(hidden_layer_sizes=(20,), max_iter=1500)>\n",
      "2022-04-13 19:20:04.862909 [ \u001b[1;94mINFO\u001b[0m  ] Training: <Clasifier vec_type=G3 trained=False model=MLPClassifier(max_iter=1500)>\n",
      "2022-04-13 19:22:21.620830 [ \u001b[1;94mINFO\u001b[0m  ] training term highlighter\n",
      "2022-04-13 19:22:32.112143 [  \u001b[1;92mOK\u001b[0m   ] done\n",
      "|█--------------------------------------------------------------------------|  0.35% labeled\n"
     ]
    }
   ],
   "source": [
    "system = HRSystem(from_scratch=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7cf365a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['room',\n",
       " 'phone',\n",
       " 'experience',\n",
       " 'unch',\n",
       " 'dp',\n",
       " 'girl',\n",
       " 'person',\n",
       " 'school',\n",
       " 'canada',\n",
       " 'oil',\n",
       " 'pfd',\n",
       " 'arrive',\n",
       " 'ltd',\n",
       " 'iro',\n",
       " 'iii',\n",
       " 'camp',\n",
       " 'motors',\n",
       " 'apply',\n",
       " 'jews',\n",
       " 'immigration',\n",
       " 'doctor',\n",
       " 'worker',\n",
       " 'lake',\n",
       " 'come',\n",
       " 'family',\n",
       " 'union',\n",
       " 'miss',\n",
       " 'halifax',\n",
       " 'labor',\n",
       " 'polish',\n",
       " 'radio',\n",
       " 'train',\n",
       " 'bedroom',\n",
       " 'toronto',\n",
       " 'body',\n",
       " 'ship',\n",
       " 'day',\n",
       " 'europe',\n",
       " 'council',\n",
       " 'office',\n",
       " 'ont',\n",
       " 'nurse',\n",
       " 'mitchell',\n",
       " 'mrs',\n",
       " 'people',\n",
       " 'sedan',\n",
       " 'george',\n",
       " 'woman',\n",
       " 'student',\n",
       " 'hall',\n",
       " 'social',\n",
       " 'howe',\n",
       " 'mother',\n",
       " 'marriage',\n",
       " 'miner',\n",
       " 'class',\n",
       " 'dennis',\n",
       " 'communists',\n",
       " 'child',\n",
       " 'close',\n",
       " 'car',\n",
       " 'death',\n",
       " 'farm',\n",
       " 'senator',\n",
       " 'communist',\n",
       " 'english',\n",
       " 'man',\n",
       " 'austria',\n",
       " 'service',\n",
       " 'country',\n",
       " 'play',\n",
       " 'price',\n",
       " 'mail',\n",
       " 'chapter',\n",
       " 'ballet',\n",
       " 'party',\n",
       " 'good',\n",
       " 'ond',\n",
       " 'accident',\n",
       " 'meet',\n",
       " 'hydro',\n",
       " 'tho',\n",
       " 'news',\n",
       " 'salary',\n",
       " 'ajax',\n",
       " 'process',\n",
       " 'want',\n",
       " 'dividend',\n",
       " 'year',\n",
       " 'glen',\n",
       " 'month',\n",
       " 'war',\n",
       " 'time',\n",
       " 'domestic',\n",
       " 'motor',\n",
       " 'community',\n",
       " 'police',\n",
       " 'ill',\n",
       " 'spy',\n",
       " 'tender',\n",
       " 'recall',\n",
       " 'canadian',\n",
       " 'week',\n",
       " 'club',\n",
       " 'like',\n",
       " 'noranda',\n",
       " 'germany',\n",
       " 'feed',\n",
       " 'plaintiff',\n",
       " 'grade',\n",
       " 'judge',\n",
       " 'soviet',\n",
       " 'know',\n",
       " 'die',\n",
       " 'snow',\n",
       " 'july',\n",
       " 'ontario',\n",
       " 'immigrants',\n",
       " 'apt',\n",
       " 'movie',\n",
       " 'parker',\n",
       " 'box',\n",
       " 'mill',\n",
       " 'aged',\n",
       " 'send',\n",
       " 'education',\n",
       " 'job',\n",
       " 'stamp',\n",
       " 'jan',\n",
       " 'team',\n",
       " 'ccf',\n",
       " 'oft',\n",
       " 'start',\n",
       " 'flag',\n",
       " 'jury',\n",
       " 'create',\n",
       " 'ottawa',\n",
       " 'leave',\n",
       " 'bride',\n",
       " 'cbl',\n",
       " 'critic',\n",
       " 'shed',\n",
       " 'hungarian',\n",
       " 'county',\n",
       " 'coleman',\n",
       " 'society',\n",
       " 'need',\n",
       " 'bar',\n",
       " 'canadians',\n",
       " 'maria',\n",
       " 'winnipeg',\n",
       " 'paper',\n",
       " 'leader',\n",
       " 'fleming',\n",
       " 'disease',\n",
       " 'sons',\n",
       " 'non',\n",
       " 'sister',\n",
       " 'wage',\n",
       " 'kick',\n",
       " 'shirley',\n",
       " 'alberta',\n",
       " 'quota',\n",
       " 'temple',\n",
       " 'count',\n",
       " 'sunday',\n",
       " 'prime',\n",
       " 'mary',\n",
       " 'berlin',\n",
       " 'dear',\n",
       " 'hunt',\n",
       " 'seed',\n",
       " 'scout',\n",
       " 'cabin',\n",
       " 'freedom',\n",
       " 'bed',\n",
       " 'legion',\n",
       " 'garden',\n",
       " 'female',\n",
       " 'scholarship',\n",
       " 'falls',\n",
       " 'marie',\n",
       " 'mimico',\n",
       " 'proud',\n",
       " 'teach',\n",
       " 'congress',\n",
       " 'shaw',\n",
       " 'soccer',\n",
       " 'happiness',\n",
       " 'employer',\n",
       " 'reserve',\n",
       " 'department',\n",
       " 'big',\n",
       " 'status',\n",
       " 'calgary',\n",
       " 'scrap',\n",
       " 'high',\n",
       " 'fire',\n",
       " 'travel',\n",
       " 'accord',\n",
       " 'business',\n",
       " 'return',\n",
       " 'repair',\n",
       " 'traffic',\n",
       " 'kennedy',\n",
       " 'great',\n",
       " 'parade',\n",
       " 'income',\n",
       " 'tor',\n",
       " 'order',\n",
       " 'jewish',\n",
       " 'statement',\n",
       " 'catholic',\n",
       " 'industry',\n",
       " 'lift',\n",
       " 'arrivals',\n",
       " 'eye',\n",
       " 'kingston',\n",
       " 'subject',\n",
       " 'steamship',\n",
       " 'campbell',\n",
       " 'island',\n",
       " 'memory',\n",
       " 'state',\n",
       " 'limited',\n",
       " 'feb',\n",
       " 'son',\n",
       " 'nov',\n",
       " 'sale',\n",
       " 'think',\n",
       " 'stock',\n",
       " 'charge',\n",
       " 'red',\n",
       " 'cottage',\n",
       " 'funeral',\n",
       " 'choose',\n",
       " 'fund',\n",
       " 'table',\n",
       " 'watch',\n",
       " 'march',\n",
       " 'hospital',\n",
       " 'run',\n",
       " 'furlong',\n",
       " 'welfare',\n",
       " 'sentence',\n",
       " 'young',\n",
       " 'eaton',\n",
       " 'coach',\n",
       " 'low',\n",
       " 'dig',\n",
       " 'museum',\n",
       " 'program',\n",
       " 'company',\n",
       " 'bus',\n",
       " 'committee',\n",
       " 'dog',\n",
       " 'sun',\n",
       " 'drew',\n",
       " 'northern',\n",
       " 'professional',\n",
       " 'states',\n",
       " 'bond',\n",
       " 'store',\n",
       " 'ami',\n",
       " 'dress',\n",
       " 'european',\n",
       " 'festival',\n",
       " 'thr',\n",
       " 'record',\n",
       " 'help',\n",
       " 'raise',\n",
       " 'cardinal',\n",
       " 'banff',\n",
       " 'ihe',\n",
       " 'medical',\n",
       " 'proof',\n",
       " 'convention',\n",
       " 'sweden',\n",
       " 'bring',\n",
       " 'long',\n",
       " 'united',\n",
       " 'house',\n",
       " 'merry',\n",
       " 'driver',\n",
       " 'coroner',\n",
       " 'benefit',\n",
       " 'flight',\n",
       " 'sign',\n",
       " 'pet',\n",
       " 'tit',\n",
       " 'plea',\n",
       " 'president',\n",
       " 'china',\n",
       " 'defendant',\n",
       " 'pepper',\n",
       " 'murder',\n",
       " 'strike',\n",
       " 'fnr',\n",
       " 'iode',\n",
       " 'yonge',\n",
       " 'find',\n",
       " 'aug',\n",
       " 'mar',\n",
       " 'ave',\n",
       " 'ford',\n",
       " 'bank',\n",
       " 'believe',\n",
       " 'church',\n",
       " 'claim',\n",
       " 'race',\n",
       " 'stenographer',\n",
       " 'pond',\n",
       " 'home',\n",
       " 'share',\n",
       " 'seek',\n",
       " 'application',\n",
       " 'compensation',\n",
       " 'val',\n",
       " 'night',\n",
       " 'world',\n",
       " 'charles',\n",
       " 'christopher',\n",
       " 'susan',\n",
       " 'clerk',\n",
       " 'explosion',\n",
       " 'hero',\n",
       " 'typist',\n",
       " 'employment',\n",
       " 'acre',\n",
       " 'saturday',\n",
       " 'lie',\n",
       " 'chevrolet',\n",
       " 'letter',\n",
       " 'dollar',\n",
       " 'open',\n",
       " 'globe',\n",
       " 'oct',\n",
       " 'hut',\n",
       " 'france',\n",
       " 'population',\n",
       " 'mile',\n",
       " 'yugoslavia',\n",
       " 'christmas',\n",
       " 'israel',\n",
       " 'housing',\n",
       " 'boat',\n",
       " 'cdn',\n",
       " 'hilda',\n",
       " 'hoy',\n",
       " 'apr',\n",
       " 'main',\n",
       " 'trade',\n",
       " 'tour',\n",
       " 'cfrb',\n",
       " 'aad',\n",
       " 'rocket',\n",
       " 'pontiac',\n",
       " 'york',\n",
       " 'eat',\n",
       " 'player',\n",
       " 'ndp',\n",
       " 'survey',\n",
       " 'way',\n",
       " 'mmi',\n",
       " 'cent',\n",
       " 'minor',\n",
       " 'insurance',\n",
       " 'trial',\n",
       " 'king',\n",
       " 'imi',\n",
       " 'role',\n",
       " 'international',\n",
       " 'ard',\n",
       " 'welland',\n",
       " 'clair',\n",
       " 'require',\n",
       " 'fur',\n",
       " 'position',\n",
       " 'force',\n",
       " 'color',\n",
       " 'women',\n",
       " 'american',\n",
       " 'german',\n",
       " 'free',\n",
       " 'existence',\n",
       " 'national',\n",
       " 'june',\n",
       " 'old',\n",
       " 'money',\n",
       " 'fare',\n",
       " 'street',\n",
       " 'appeal',\n",
       " 'floor',\n",
       " 'blind',\n",
       " 'nbc',\n",
       " 'charity',\n",
       " 'davidson',\n",
       " 'toy',\n",
       " 'found',\n",
       " 'foot',\n",
       " 'gibson',\n",
       " 'increase',\n",
       " 'engineer',\n",
       " 'building',\n",
       " 'board',\n",
       " 'tax',\n",
       " 'hair',\n",
       " 'defeat',\n",
       " 'reg',\n",
       " 'lodge',\n",
       " 'mines',\n",
       " 'culture',\n",
       " 'john',\n",
       " 'aid',\n",
       " 'election',\n",
       " 'minister',\n",
       " 'communism',\n",
       " 'attitude',\n",
       " 'army',\n",
       " 'davis',\n",
       " 'sail',\n",
       " 'seven',\n",
       " 'kitchener',\n",
       " 'wife',\n",
       " 'royal',\n",
       " 'treaty',\n",
       " 'brain',\n",
       " 'mutual',\n",
       " 'tire',\n",
       " 'court',\n",
       " 'payable',\n",
       " 'hotel',\n",
       " 'liberal',\n",
       " 'include',\n",
       " 'french',\n",
       " 'col',\n",
       " 'herbert',\n",
       " 'priest',\n",
       " 'ton',\n",
       " 'period',\n",
       " 'macleod',\n",
       " 'near',\n",
       " 'detroit',\n",
       " 'award',\n",
       " 'route',\n",
       " 'white',\n",
       " 'pay',\n",
       " 'rate',\n",
       " 'cost',\n",
       " 'total',\n",
       " 'profit',\n",
       " 'music',\n",
       " 'course',\n",
       " 'theatre',\n",
       " 'baby',\n",
       " 'vessel',\n",
       " 'unit',\n",
       " 'thursday',\n",
       " 'wool',\n",
       " 'radar',\n",
       " 'atomic',\n",
       " 'jamaica',\n",
       " 'filter',\n",
       " '12th',\n",
       " 'member',\n",
       " 'category',\n",
       " 'timmins',\n",
       " 'association',\n",
       " 'summer',\n",
       " 'town',\n",
       " 'gold',\n",
       " 'engineers',\n",
       " 'engineering',\n",
       " 'hill',\n",
       " 'unemployment',\n",
       " 'unemployed',\n",
       " 'pain',\n",
       " 'feel',\n",
       " 'divorce',\n",
       " 'april',\n",
       " 'corporation',\n",
       " 'tca',\n",
       " 'control',\n",
       " 'rent',\n",
       " 'auto',\n",
       " 'london',\n",
       " 'holy',\n",
       " 'drive',\n",
       " 'hamilton',\n",
       " 'aaa',\n",
       " 'british',\n",
       " 'capital',\n",
       " 'exhibit',\n",
       " 'sen',\n",
       " 'loan',\n",
       " 'coffee',\n",
       " 'level',\n",
       " 'morgan',\n",
       " 'opportunity',\n",
       " 'cbc',\n",
       " 'barber',\n",
       " 'wheat',\n",
       " 'map',\n",
       " 'australia',\n",
       " 'nuclear',\n",
       " 'stewart',\n",
       " 'cancer',\n",
       " 'payment',\n",
       " 'judgment',\n",
       " 'coal',\n",
       " 'mortgage',\n",
       " 'dom',\n",
       " 'dec',\n",
       " 'cross',\n",
       " 'nnd',\n",
       " 'art',\n",
       " 'bill',\n",
       " 'fto',\n",
       " 'steel',\n",
       " 'stable',\n",
       " 'hardwood',\n",
       " 'health',\n",
       " 'lot',\n",
       " 'russia',\n",
       " 'read',\n",
       " 'britain',\n",
       " 'august',\n",
       " 'group',\n",
       " 'bid',\n",
       " 'coat',\n",
       " 'telephone',\n",
       " 'note',\n",
       " 'ask',\n",
       " 'area',\n",
       " 'vote',\n",
       " 'boy',\n",
       " 'public',\n",
       " 'maclean',\n",
       " 'wear',\n",
       " 'grant',\n",
       " 'principal',\n",
       " 'till',\n",
       " 'pound',\n",
       " 'dinner',\n",
       " 'norman',\n",
       " 'face',\n",
       " 'friend',\n",
       " 'hour',\n",
       " 'tournament',\n",
       " 'clothing',\n",
       " 'aircraft',\n",
       " 'convert',\n",
       " 'carry',\n",
       " 'grain',\n",
       " 'pat',\n",
       " 'brand',\n",
       " 'win',\n",
       " 'downtown',\n",
       " 'today',\n",
       " 'dealer',\n",
       " 'personnel',\n",
       " 'marine',\n",
       " 'shell',\n",
       " 'junior',\n",
       " 'file',\n",
       " 'league',\n",
       " 'sat',\n",
       " 'food',\n",
       " 'cbs',\n",
       " 'candidate',\n",
       " 'golf',\n",
       " 'book',\n",
       " 'life',\n",
       " 'elderly',\n",
       " 'caa',\n",
       " 'tin',\n",
       " 'truman',\n",
       " 'cold',\n",
       " 'meeting',\n",
       " 'work',\n",
       " 'title',\n",
       " 'display',\n",
       " 'final',\n",
       " 'province',\n",
       " 'father',\n",
       " 'report',\n",
       " 'instant',\n",
       " 'west',\n",
       " 'north',\n",
       " 'sports',\n",
       " 'speak',\n",
       " 'dean',\n",
       " 'sport',\n",
       " 'voyage',\n",
       " 'maine',\n",
       " 'thf',\n",
       " 'satisfaction',\n",
       " 'point',\n",
       " 'entry',\n",
       " 'rev',\n",
       " 'air',\n",
       " 'light',\n",
       " 'stafford',\n",
       " 'sot',\n",
       " 'daily',\n",
       " 'carrier',\n",
       " 'buy',\n",
       " 'december',\n",
       " 'february',\n",
       " 'sept',\n",
       " 'robert',\n",
       " 'round',\n",
       " 'mall',\n",
       " 'tell',\n",
       " 'collegiate',\n",
       " 'relief',\n",
       " 'claude',\n",
       " 'sharp',\n",
       " '28th',\n",
       " 'authority',\n",
       " 'fast',\n",
       " 'auditorium',\n",
       " 'institute',\n",
       " 'energy',\n",
       " 'ago',\n",
       " 'suite',\n",
       " 'dry',\n",
       " 'bell',\n",
       " 'communication',\n",
       " 'sir',\n",
       " 'gas',\n",
       " 'par',\n",
       " 'tip',\n",
       " 'florida',\n",
       " 'learn',\n",
       " 'prl',\n",
       " 'album',\n",
       " 'rector',\n",
       " 'laird',\n",
       " 'government',\n",
       " 'douglas',\n",
       " 'live',\n",
       " 'spring',\n",
       " 'profession',\n",
       " 'age',\n",
       " 'borrow',\n",
       " 'plane',\n",
       " 'referee',\n",
       " 'fargo',\n",
       " 'press',\n",
       " 'september',\n",
       " 'manning',\n",
       " 'martin',\n",
       " 'apple',\n",
       " 'winner',\n",
       " 'thp',\n",
       " 'nal',\n",
       " 'orillia',\n",
       " 'mouth',\n",
       " '13s',\n",
       " 'youth',\n",
       " 'chev',\n",
       " 'dept',\n",
       " 'save',\n",
       " 'library',\n",
       " 'uranium',\n",
       " 'surplus',\n",
       " 'permanent',\n",
       " 'cpr',\n",
       " 'pension',\n",
       " 'ion',\n",
       " 'consultant',\n",
       " 'date',\n",
       " 'broadloom',\n",
       " 'clause',\n",
       " 'elisabeth',\n",
       " 'future',\n",
       " 'edmund',\n",
       " 'tnd',\n",
       " 'hit',\n",
       " 'iso',\n",
       " 'trophy',\n",
       " 'rifle',\n",
       " 'wood',\n",
       " 'bird',\n",
       " 'cruise',\n",
       " 'cotton',\n",
       " 'liquor',\n",
       " 'volkswagen',\n",
       " 'battery',\n",
       " 'fat',\n",
       " 'decide',\n",
       " 'look',\n",
       " 'touchdown',\n",
       " 'arena',\n",
       " 'pork',\n",
       " 'simpson',\n",
       " 'lat',\n",
       " 'chief',\n",
       " 'anne',\n",
       " 'fly',\n",
       " 'left',\n",
       " 'super',\n",
       " 'export',\n",
       " 'column',\n",
       " 'washer',\n",
       " 'sudbury',\n",
       " 'cambridge',\n",
       " 'tear',\n",
       " 'constitutional',\n",
       " 'que',\n",
       " 'tavern',\n",
       " 'thomas',\n",
       " 'factory',\n",
       " 'premier',\n",
       " 'battalion',\n",
       " 'economic',\n",
       " 'austin',\n",
       " 'cadillac',\n",
       " 'warranty',\n",
       " 'corner',\n",
       " 'tea',\n",
       " 'iron',\n",
       " 'volunteer',\n",
       " 'poland',\n",
       " 'ward',\n",
       " 'action',\n",
       " 'temperance',\n",
       " 'niagara',\n",
       " 'mav',\n",
       " 'lead',\n",
       " 'little',\n",
       " 'set',\n",
       " 'motion',\n",
       " 'eagle',\n",
       " 'spray',\n",
       " 'avk',\n",
       " 'tropical',\n",
       " 'pearson',\n",
       " 'fred',\n",
       " 'arrived',\n",
       " 'newspaper',\n",
       " 'swiss',\n",
       " 'weather',\n",
       " 'victor',\n",
       " 'trust',\n",
       " 'diefenbaker',\n",
       " 'common',\n",
       " 'treatment',\n",
       " 'tariff',\n",
       " 'film',\n",
       " 'appointment',\n",
       " 'gordon',\n",
       " 'plymouth',\n",
       " 'clancy',\n",
       " 'scotia',\n",
       " 'oven',\n",
       " 'colour',\n",
       " 'rto',\n",
       " 'tomorrow',\n",
       " 'reward',\n",
       " 'rubber',\n",
       " 'system',\n",
       " 'land',\n",
       " 'clean',\n",
       " 'tile',\n",
       " 'joe',\n",
       " 'end',\n",
       " 'railway',\n",
       " 'available',\n",
       " 'ann',\n",
       " 'extent',\n",
       " 'budget',\n",
       " 'property',\n",
       " 'desire',\n",
       " 'quebec',\n",
       " 'deposit',\n",
       " 'window',\n",
       " 'holiday',\n",
       " 'daughter',\n",
       " 'engine',\n",
       " 'line',\n",
       " 'ski',\n",
       " 'research',\n",
       " 'cricket',\n",
       " 'david',\n",
       " 'electric',\n",
       " 'lor',\n",
       " 'fox',\n",
       " 'nursing',\n",
       " 'number',\n",
       " 'nixon',\n",
       " 'walker',\n",
       " 'notice',\n",
       " 'supply',\n",
       " 'oha',\n",
       " 'yard',\n",
       " 'consumer',\n",
       " 'friday',\n",
       " 'hockey',\n",
       " 'ftl',\n",
       " 'circulation',\n",
       " 'famous',\n",
       " 'civil',\n",
       " 'arrest',\n",
       " 'machine',\n",
       " 'hear',\n",
       " 'nation',\n",
       " 'natural',\n",
       " 'defense',\n",
       " 'lumber',\n",
       " 'hats',\n",
       " 'plant',\n",
       " 'water',\n",
       " 'automatic',\n",
       " 'furniture',\n",
       " 'originally',\n",
       " 'parliamentary',\n",
       " 'rcaf',\n",
       " 'import',\n",
       " 'ground',\n",
       " 'nato',\n",
       " 'varsity',\n",
       " 'estate',\n",
       " 'nervous',\n",
       " 'lib',\n",
       " 'app',\n",
       " 'actor',\n",
       " 'port',\n",
       " 'silver',\n",
       " 'brotherhood',\n",
       " 'guild',\n",
       " 'limit',\n",
       " 'tht',\n",
       " 'beaver',\n",
       " 'roll',\n",
       " 'dominion',\n",
       " 'wave',\n",
       " 'forest',\n",
       " 'veteran',\n",
       " 'salle',\n",
       " 'second',\n",
       " 'isa',\n",
       " 'identity',\n",
       " 'maid',\n",
       " 'case',\n",
       " 'alliance',\n",
       " 'prizes',\n",
       " 'chocolate',\n",
       " 'columbia',\n",
       " 'city',\n",
       " 'stay',\n",
       " 'mil',\n",
       " 'ban',\n",
       " 'magic',\n",
       " 'seal',\n",
       " 'style',\n",
       " 'brigade',\n",
       " 'ment',\n",
       " 'warm',\n",
       " 'range',\n",
       " 'comfort',\n",
       " 'prize',\n",
       " 'false',\n",
       " 'drop',\n",
       " 'salmon',\n",
       " 'wagner',\n",
       " 'abbott',\n",
       " 'contest',\n",
       " 'sex',\n",
       " 'plate',\n",
       " 'construction',\n",
       " 'size',\n",
       " 'paul',\n",
       " 'sunny',\n",
       " 'criminal',\n",
       " 'luxe',\n",
       " 'small',\n",
       " 'fish',\n",
       " 'article',\n",
       " 'cheese',\n",
       " 'manager',\n",
       " 'tap',\n",
       " 'act',\n",
       " 'truck',\n",
       " 'amateur',\n",
       " 'game',\n",
       " 'los',\n",
       " 'brampton',\n",
       " 'scarboro',\n",
       " 'sault',\n",
       " 'flavour',\n",
       " 'cream',\n",
       " 'skin',\n",
       " 'dish',\n",
       " 'data',\n",
       " 'serve',\n",
       " 'inch',\n",
       " 'appoint',\n",
       " 'mills',\n",
       " 'don',\n",
       " 'burns',\n",
       " 'processing',\n",
       " 'booklet',\n",
       " 'effort',\n",
       " 'stainless',\n",
       " 'bag',\n",
       " 'iis',\n",
       " 'persons',\n",
       " 'tables',\n",
       " 'row',\n",
       " 'husband',\n",
       " 'climb',\n",
       " 'heat',\n",
       " 'noon',\n",
       " 'design',\n",
       " 'allan',\n",
       " 'bay',\n",
       " 'plan',\n",
       " 'goodyear',\n",
       " 'trip',\n",
       " 'hope',\n",
       " 'campaign',\n",
       " 'hearing',\n",
       " 'express',\n",
       " 'tion',\n",
       " 'bermuda',\n",
       " 'bldg',\n",
       " 'til',\n",
       " 'large',\n",
       " 'intermediate',\n",
       " 'atom',\n",
       " 'quarter',\n",
       " 'irish',\n",
       " 'independent',\n",
       " 'macdonald',\n",
       " 'rosedale',\n",
       " 'christ',\n",
       " 'bantam',\n",
       " 'regular',\n",
       " 'clearing',\n",
       " 'james',\n",
       " 'write',\n",
       " 'oldsmobile',\n",
       " 'burn',\n",
       " 'suit',\n",
       " 'doubt',\n",
       " 'islands',\n",
       " '10s',\n",
       " 'gift',\n",
       " 'renfrew',\n",
       " 'hat',\n",
       " 'adelaide',\n",
       " 'mention',\n",
       " 'quote',\n",
       " 'sep',\n",
       " 'thompson',\n",
       " 'cne',\n",
       " 'wanted',\n",
       " 'appliance',\n",
       " 'ymca',\n",
       " 'membership',\n",
       " 'gardiner',\n",
       " 'market',\n",
       " '4th',\n",
       " 'warn',\n",
       " 'cowan',\n",
       " 'anti',\n",
       " 'favor',\n",
       " 'fit',\n",
       " 'shot',\n",
       " 'button',\n",
       " 'whisky',\n",
       " 'fashion',\n",
       " 'quality',\n",
       " 'marry',\n",
       " 'beach',\n",
       " 'general',\n",
       " 'woodbine',\n",
       " 'parking',\n",
       " 'eglinton',\n",
       " 'ticket',\n",
       " 'ballroom',\n",
       " 'wben',\n",
       " 'interest',\n",
       " 'prairie',\n",
       " 'ffl',\n",
       " 'grey',\n",
       " 'support',\n",
       " 'problem',\n",
       " 'law',\n",
       " 'admit',\n",
       " 'nat',\n",
       " 'nightly',\n",
       " 'ice',\n",
       " 'graham',\n",
       " 'tke',\n",
       " 'twice',\n",
       " 'happy',\n",
       " 'best',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.term_highlighter.sorted_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aade27c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system._save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ccc581",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 19:25:02.938414 [ \u001b[1;94mINFO\u001b[0m  ] Re-trained. Computing suggestions...\n",
      "2022-04-13 19:25:03.191648 [ \u001b[1;94mINFO\u001b[0m  ] Making predictions over 50000 with model: <Clasifier vec_type=B trained=True model=MLPClassifier(hidden_layer_sizes=(20,), max_iter=1500)>\n",
      "yhat1.shape=(50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 19:25:19.009832 [ \u001b[1;94mINFO\u001b[0m  ] Descarding 43960 articles.\n",
      "2022-04-13 19:25:19.011432 [ \u001b[1;94mINFO\u001b[0m  ] Making predictions over 6040 with model: <Clasifier vec_type=G3 trained=True model=MLPClassifier(max_iter=1500)>\n",
      "2022-04-13 19:25:19.759985 [ \u001b[1;94mINFO\u001b[0m  ] Descarding 5298 articles.\n",
      "yhat1.shape=(742,)\n",
      "yhat2.shape=(742,)\n",
      "2022-04-13 19:25:19.761057 [ \u001b[1;94mINFO\u001b[0m  ] Making predictions over 742 with model: <TermHighlighter model=LogisticRegression(C=1) trained=True vocab=<title, ..., new>>\n",
      "yhat4.shape=(742,)\n",
      "2022-04-13 19:25:19.904366 [ \u001b[1;94mINFO\u001b[0m  ] Number of relevant articles found: 30020 (ESTIMATED)\n",
      "2022-04-13 19:25:19.914717 [ \u001b[1;94mINFO\u001b[0m  ] Moving 10 unlabeled suggestions from unlabeled data (2042213 - 10)\n",
      "|█--------------------------------------------------------------------------|  0.35% labeled\n",
      " |██------------------------------------------------------------------------|  1.47% remaining relevant (estimated)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1925f004fd4784b9d2c06b884928f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec2d7db49db48d3ba23ce2520279d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Relevant', style=ButtonStyle()), Button(description='Irrelev…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8840e98aa44edb8ad03a31723eecbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation done.\n"
     ]
    }
   ],
   "source": [
    "system.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a765b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d0d2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7e1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed1477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575fcc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6409ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ffee5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d315eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc920cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3217b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d60f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a8a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a7a3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c5f4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c93eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "214b893c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-31 19:51:58.021909 [  \u001b[1;92mOK\u001b[0m   ] Done\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "300c72a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-31 19:38:50.923323 [\u001b[1;31mWARNING\u001b[0m] Computing labeled data\n",
      "2022-03-31 19:38:51.017451 [ \u001b[1;94mINFO\u001b[0m  ] Retrieving unlabeled data from disk\n",
      "2022-03-31 19:39:01.536784 [ \u001b[1;94mINFO\u001b[0m  ] Number of unlabeled documents:    300,000\n",
      "2022-03-31 19:39:01.536902 [ \u001b[1;94mINFO\u001b[0m  ] Number of labeled documents:        7,104\n",
      "2022-03-31 19:39:01.537728 [ \u001b[1;94mINFO\u001b[0m  ] Training model\n",
      "2022-03-31 19:39:01.538760 [ \u001b[1;94mINFO\u001b[0m  ] Training: <Clasifier vec_type=B trained=False model=SVC(C=1, kernel='linear', probability=True)>\n",
      "2022-03-31 19:39:26.899966 [ \u001b[1;94mINFO\u001b[0m  ] Training: <Clasifier vec_type=G3 trained=False model=SVC(C=7, probability=True)>\n",
      "2022-03-31 19:39:27.448747 [ \u001b[1;94mINFO\u001b[0m  ] Training: <Clasifier vec_type=G6 trained=False model=SVC(C=1, kernel='poly', probability=True)>\n",
      "2022-03-31 19:39:28.717571 [ \u001b[1;94mINFO\u001b[0m  ] training term highlighter\n",
      "2022-03-31 19:43:00.193110 [  \u001b[1;92mOK\u001b[0m   ] done\n",
      "|██-------------------------------------------------------------------------|  2.31% labeled\n"
     ]
    }
   ],
   "source": [
    "system = HRSystem(from_scratch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94bb8388",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-31 19:43:19.008790 [ \u001b[1;94mINFO\u001b[0m  ] Re-trained. Computing suggestions...\n",
      "yhat1.shape=(20000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhat1.shape=(7259,)\n",
      "yhat2.shape=(7259,)\n",
      "yhat3.shape=(7259,)\n",
      "yhat4.shape=(7259,)\n",
      "yhat=[0.71076439 0.82420983 0.87136826 ... 0.75436362 0.87291166 0.67581019]\n",
      "yhat=[0.96299861 0.95894536 0.95820286 ... 0.5348342  0.52992759 0.51538287]\n",
      "2022-03-31 19:46:09.881373 [ \u001b[1;94mINFO\u001b[0m  ] Number of relevant articles found: 108885 (ESTIMATED)\n",
      "2022-03-31 19:46:09.883425 [ \u001b[1;94mINFO\u001b[0m  ] Moving 10 unlabeled suggestions from unlabeled data (299990 - 10)\n",
      "|██-------------------------------------------------------------------------|  2.31% labeled\n",
      "  |███████████████████████████----------------------------------------------| 36.30% remaining relevant (estimated)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfaba647e7864bfa9e6cbbfa98f2650d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b158122ac47f45789c811528686a870c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Relevant', style=ButtonStyle()), Button(description='Irrelev…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cbbc88f35e48148e8c6b9530533fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5feba608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f277d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "['dp',\n",
    " 'displace',\n",
    " 'person',\n",
    " 'canada',\n",
    " 'camp',\n",
    " 'ii',\n",
    " 'come',\n",
    " 'title',\n",
    " 'arrive',\n",
    " 'ft',\n",
    " 'europe',\n",
    " 'immigrant',\n",
    " 'girl',\n",
    " 'ad',\n",
    " 'find',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "446e0320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dp',\n",
       " 'canada',\n",
       " 'person',\n",
       " 'displace',\n",
       " 'ii',\n",
       " 'camp',\n",
       " 't',\n",
       " 'm',\n",
       " 'room',\n",
       " 'worker',\n",
       " 'ltd',\n",
       " 'st',\n",
       " 'sale',\n",
       " 'come',\n",
       " 'ft',\n",
       " 'work',\n",
       " 'refugee',\n",
       " 'pr',\n",
       " 'immigration',\n",
       " 'arrive',\n",
       " 'l',\n",
       " 'europe',\n",
       " 'experience',\n",
       " 'phone',\n",
       " 'canadian',\n",
       " 'toronto',\n",
       " 'immigrant',\n",
       " 'girl',\n",
       " 'll',\n",
       " 'germany',\n",
       " 'find',\n",
       " 'german',\n",
       " 'unch',\n",
       " 'bring',\n",
       " 'oil',\n",
       " 'wa',\n",
       " 'r',\n",
       " 'price',\n",
       " 'office',\n",
       " 'night',\n",
       " 'require',\n",
       " 'council',\n",
       " 'today',\n",
       " 'company',\n",
       " 'hi',\n",
       " 'polish',\n",
       " 'high',\n",
       " 'co',\n",
       " 'apply',\n",
       " 'man',\n",
       " 'job',\n",
       " 'li',\n",
       " 'ad',\n",
       " 'tv',\n",
       " 'labor',\n",
       " 'people',\n",
       " 'il',\n",
       " 'estate',\n",
       " 'si',\n",
       " 'tn',\n",
       " 'want',\n",
       " 'title',\n",
       " 'salary',\n",
       " 'school',\n",
       " 'news',\n",
       " 'member',\n",
       " 'country',\n",
       " 'box',\n",
       " 'low',\n",
       " 'speak',\n",
       " 'jewish',\n",
       " 'cent',\n",
       " 'leave',\n",
       " 'communist',\n",
       " 'union',\n",
       " 'n',\n",
       " 'cp',\n",
       " 'ont',\n",
       " 'rr',\n",
       " 'group',\n",
       " 'official',\n",
       " 'tor',\n",
       " 'miss',\n",
       " 'ir',\n",
       " 'al',\n",
       " 'limit',\n",
       " 'good',\n",
       " 'united',\n",
       " 'month',\n",
       " 'tr',\n",
       " 'woman',\n",
       " 'fi',\n",
       " 'sport',\n",
       " 'nt',\n",
       " 'lake',\n",
       " 'bedroom',\n",
       " 'service',\n",
       " 'child',\n",
       " 'ml',\n",
       " 'date',\n",
       " 'position',\n",
       " 'lot',\n",
       " 'v',\n",
       " 'nr',\n",
       " 'dr',\n",
       " 'war',\n",
       " 'tell',\n",
       " 'j',\n",
       " 'increase',\n",
       " 'tt',\n",
       " 'em',\n",
       " 'meeting',\n",
       " 'english',\n",
       " 'ai',\n",
       " 'rate',\n",
       " 'business',\n",
       " 'mm',\n",
       " 'hospital',\n",
       " 'f',\n",
       " 'vi',\n",
       " 'yesterday',\n",
       " 'mi',\n",
       " 'return',\n",
       " 'ri',\n",
       " 'nf',\n",
       " 'food',\n",
       " 'la',\n",
       " 'train',\n",
       " 'pi',\n",
       " 'law',\n",
       " 'stock',\n",
       " 'admit',\n",
       " 'bond',\n",
       " 'grade',\n",
       " 'domestic',\n",
       " 'oct',\n",
       " 'air',\n",
       " 'h',\n",
       " 'mr',\n",
       " 'dollar',\n",
       " 'place',\n",
       " 'ma',\n",
       " 'public',\n",
       " 'help',\n",
       " 'import',\n",
       " 'ontario',\n",
       " 'rt',\n",
       " 'mrs',\n",
       " 'year',\n",
       " 'yonge',\n",
       " 'globe',\n",
       " 'nd',\n",
       " 'e',\n",
       " 'iv',\n",
       " 'charge',\n",
       " 'mary',\n",
       " 'miner',\n",
       " 'pfd',\n",
       " 'motors',\n",
       " 'ti',\n",
       " 'music',\n",
       " 'ukrainian',\n",
       " 'film',\n",
       " 'hu',\n",
       " 'mail',\n",
       " 'problem',\n",
       " 'cbl',\n",
       " 'police',\n",
       " 'summer',\n",
       " 'kill',\n",
       " 'th',\n",
       " 'report',\n",
       " 'european',\n",
       " 'walker',\n",
       " 'ro',\n",
       " 'lt',\n",
       " 'arrival',\n",
       " 'bay',\n",
       " 'remain',\n",
       " 'lor',\n",
       " 'wife',\n",
       " 'feel',\n",
       " 'day',\n",
       " 'hill',\n",
       " 'excellent',\n",
       " 'try',\n",
       " 'meet',\n",
       " 'famous',\n",
       " 'ing',\n",
       " 'ot',\n",
       " 'language',\n",
       " 'ss',\n",
       " 'private',\n",
       " 'little',\n",
       " 's',\n",
       " 'hope',\n",
       " 'fl',\n",
       " 'kitchen',\n",
       " 'modern',\n",
       " 'issue',\n",
       " 'manager',\n",
       " 'austria',\n",
       " 'white',\n",
       " 'bank',\n",
       " 'display',\n",
       " 'ford',\n",
       " 'radio',\n",
       " 'jews',\n",
       " 'grant',\n",
       " 'writer',\n",
       " 'halifax',\n",
       " 'citizen',\n",
       " 'million',\n",
       " 'recently',\n",
       " 'way',\n",
       " 'july',\n",
       " 'british',\n",
       " 'friend',\n",
       " 'hungarian',\n",
       " 'movie',\n",
       " 'large',\n",
       " 'motor',\n",
       " 'face',\n",
       " 'jj',\n",
       " 'tl',\n",
       " 'o',\n",
       " 'know',\n",
       " 'limited',\n",
       " 'believe',\n",
       " 'sell',\n",
       " 'think',\n",
       " 'bureau',\n",
       " 'c',\n",
       " 'fight',\n",
       " 'contract',\n",
       " 'iro',\n",
       " 'live',\n",
       " 'wave',\n",
       " 'deposit',\n",
       " 'coal',\n",
       " 'family',\n",
       " 'cross',\n",
       " 'claim',\n",
       " 'ave',\n",
       " 'notice',\n",
       " 'industry',\n",
       " 'k',\n",
       " 'ci',\n",
       " 'spend',\n",
       " 'rn',\n",
       " 'cbs',\n",
       " 'fr',\n",
       " 'aug',\n",
       " 'tender',\n",
       " 'io',\n",
       " 'cr',\n",
       " 'happy',\n",
       " 'shop',\n",
       " 'relative',\n",
       " 'el',\n",
       " 'list',\n",
       " 'ottawa',\n",
       " 'north',\n",
       " 'iii',\n",
       " 'stay',\n",
       " 'pass',\n",
       " 'hat',\n",
       " 'garage',\n",
       " 'welfare',\n",
       " 'cost',\n",
       " 'learn',\n",
       " 'county',\n",
       " 'recent',\n",
       " 'red',\n",
       " 'employ',\n",
       " 'denmark',\n",
       " 'ji',\n",
       " 'product',\n",
       " 'freedom',\n",
       " 'rev',\n",
       " 'fall',\n",
       " 'oo',\n",
       " 'time',\n",
       " 'student',\n",
       " 'policy',\n",
       " 'level',\n",
       " 'mo',\n",
       " 'le',\n",
       " 'carry',\n",
       " 'credit',\n",
       " 'nnd',\n",
       " 'world',\n",
       " 'market',\n",
       " 'dionne',\n",
       " 'double',\n",
       " 'com',\n",
       " 'hold',\n",
       " 'break',\n",
       " 'arc',\n",
       " 'rd',\n",
       " 'trust',\n",
       " 'christmas',\n",
       " 'present',\n",
       " 'male',\n",
       " 'late',\n",
       " 'play',\n",
       " 'principal',\n",
       " 'information',\n",
       " 'newcomer',\n",
       " 'etc',\n",
       " 'announce',\n",
       " 'father',\n",
       " 'demand',\n",
       " 'living',\n",
       " 'read',\n",
       " 'shall',\n",
       " 'd',\n",
       " 'ni',\n",
       " 'ur',\n",
       " 'life',\n",
       " 'montreal',\n",
       " 'ond',\n",
       " 'ol',\n",
       " 'old',\n",
       " 'insurance',\n",
       " 'er',\n",
       " 'friday',\n",
       " 'save',\n",
       " 'flee',\n",
       " 'weather',\n",
       " 'motion',\n",
       " 'write',\n",
       " 'palestine',\n",
       " 'p',\n",
       " 'comfort',\n",
       " 'pound',\n",
       " 'fo',\n",
       " 'extra',\n",
       " 'communism',\n",
       " 'floor',\n",
       " 'marketing',\n",
       " 'g',\n",
       " 'size',\n",
       " 'plain',\n",
       " 'september',\n",
       " 'hear',\n",
       " 'west',\n",
       " 'mt',\n",
       " 'column',\n",
       " 'driver',\n",
       " 'tm',\n",
       " 'tion',\n",
       " 'nazi',\n",
       " 'die',\n",
       " 'housing',\n",
       " 'plaintiff',\n",
       " 'soon',\n",
       " 'nbc',\n",
       " 'quebec',\n",
       " 'enter',\n",
       " 'particular',\n",
       " 'nurse',\n",
       " 'metropolitan',\n",
       " 'crash',\n",
       " 'till',\n",
       " 'early',\n",
       " 'u',\n",
       " 'offer',\n",
       " 'franc',\n",
       " 'board',\n",
       " 'baby',\n",
       " 'rl',\n",
       " 'employment',\n",
       " 'reach',\n",
       " 'homemaker',\n",
       " 'organization',\n",
       " 'ra',\n",
       " 'defendant',\n",
       " 'pl',\n",
       " 'lu',\n",
       " 'seaway',\n",
       " 'advertising',\n",
       " 'ru',\n",
       " 'telephone',\n",
       " '1st',\n",
       " 'production',\n",
       " 'ul',\n",
       " 'nov',\n",
       " 'sl',\n",
       " 'december',\n",
       " 'association',\n",
       " 'industrial',\n",
       " 'cfrb',\n",
       " 'et',\n",
       " 'laborer',\n",
       " 'russian',\n",
       " 'employer',\n",
       " 'ill',\n",
       " 'property',\n",
       " 'col',\n",
       " 'house',\n",
       " 'death',\n",
       " 'chapter',\n",
       " 'plan',\n",
       " 'cn',\n",
       " 'freight',\n",
       " 'dining',\n",
       " 'machine',\n",
       " 'general',\n",
       " 'ha',\n",
       " 'able',\n",
       " 'major',\n",
       " 'int',\n",
       " 'citizenship',\n",
       " 'junior',\n",
       " 'appointment',\n",
       " 'par',\n",
       " 'lithuanian',\n",
       " 'km',\n",
       " 'reason',\n",
       " 'un',\n",
       " 'youth',\n",
       " 'professional',\n",
       " 'opportunity',\n",
       " 'bath',\n",
       " 'ton',\n",
       " 'native',\n",
       " 'seek',\n",
       " 'britain',\n",
       " 'railway',\n",
       " 'fully',\n",
       " 'ox',\n",
       " 'poland',\n",
       " 'nl',\n",
       " 'jury',\n",
       " 'op',\n",
       " 'ui',\n",
       " 'bruce',\n",
       " 'sud',\n",
       " 'practice',\n",
       " 'university',\n",
       " 'iu',\n",
       " 'escape',\n",
       " 'rf',\n",
       " 'east',\n",
       " 'aboard',\n",
       " 'applicant',\n",
       " 'wi',\n",
       " 'cdn',\n",
       " 'ihc',\n",
       " 'buy',\n",
       " 'letter',\n",
       " 'agree',\n",
       " 'payable',\n",
       " 'trade',\n",
       " 'decline',\n",
       " 'volvo',\n",
       " 'zone',\n",
       " 'term',\n",
       " 'boy',\n",
       " 'george',\n",
       " 'case',\n",
       " 'locate',\n",
       " 'wben',\n",
       " 'acre',\n",
       " 'cash',\n",
       " 'pen',\n",
       " 'walk',\n",
       " 'rock',\n",
       " 'bear',\n",
       " 'wt',\n",
       " 'jl',\n",
       " 'lady',\n",
       " 'couple',\n",
       " 'hut',\n",
       " 'concentration',\n",
       " 's3',\n",
       " 'undersigned',\n",
       " 'department',\n",
       " 'dom',\n",
       " 'england',\n",
       " 'bloor',\n",
       " 'judge',\n",
       " 'monday',\n",
       " 'mall',\n",
       " 'af',\n",
       " 'jr',\n",
       " 'add',\n",
       " 'ho',\n",
       " 'dairy',\n",
       " 'salesman',\n",
       " 'cottage',\n",
       " 'confidence',\n",
       " 'nations',\n",
       " 'ie',\n",
       " 'bad',\n",
       " 'tho',\n",
       " 'vt',\n",
       " 'injure',\n",
       " 'joseph',\n",
       " 'parker',\n",
       " 'daughter',\n",
       " 'kitchener',\n",
       " 'catholic',\n",
       " 'homeland',\n",
       " 'ts',\n",
       " 'october',\n",
       " 'agent',\n",
       " 'federal',\n",
       " 'right',\n",
       " 'ij',\n",
       " 'w',\n",
       " 'entry',\n",
       " 'fireplace',\n",
       " 'system',\n",
       " 'sen',\n",
       " 'assistant',\n",
       " 'let',\n",
       " 'danish',\n",
       " 'nil',\n",
       " 'pa',\n",
       " 'qualification',\n",
       " 'blue',\n",
       " 'cas',\n",
       " 'february',\n",
       " 'real',\n",
       " 'mitchell',\n",
       " 'oi',\n",
       " 'exchange',\n",
       " 'ba',\n",
       " 'channel',\n",
       " 'attend',\n",
       " 'look',\n",
       " 'ch',\n",
       " 'hair',\n",
       " 'tonight',\n",
       " 'national',\n",
       " 'ywca',\n",
       " 'rent',\n",
       " 'bar',\n",
       " 'fin',\n",
       " 'settle',\n",
       " 'nn',\n",
       " 'avenue',\n",
       " 'age',\n",
       " 'marriage',\n",
       " 'fun',\n",
       " 'long',\n",
       " 'york',\n",
       " 'quality',\n",
       " 'export',\n",
       " 'port',\n",
       " 'ln',\n",
       " 'dividend',\n",
       " 'realtor',\n",
       " 'mean',\n",
       " 'cana',\n",
       " 'orphan',\n",
       " 'veteran',\n",
       " 'gold',\n",
       " 'xc',\n",
       " 'son',\n",
       " 'ar',\n",
       " 'cat',\n",
       " 'ballet',\n",
       " 'tu',\n",
       " 'bathroom',\n",
       " 'land',\n",
       " 'wl',\n",
       " 'number',\n",
       " 'share',\n",
       " 'condition',\n",
       " 'upper',\n",
       " 'ia',\n",
       " 'physical',\n",
       " 'textile',\n",
       " 'hand',\n",
       " 'available',\n",
       " 'dec',\n",
       " 'judgment',\n",
       " 'appeal',\n",
       " 'b',\n",
       " 'rosedale',\n",
       " 'statement',\n",
       " 'finance',\n",
       " 'grand',\n",
       " 'doctor',\n",
       " 'team',\n",
       " 'allowance',\n",
       " 'difficulty',\n",
       " 'navy',\n",
       " 'pre',\n",
       " 'rabbi',\n",
       " 'road',\n",
       " 'mar',\n",
       " 'cm',\n",
       " 'balance',\n",
       " 'wage',\n",
       " 'victim',\n",
       " 'turn',\n",
       " 'ki',\n",
       " 'dian',\n",
       " 'soviet',\n",
       " 'plus',\n",
       " 'line',\n",
       " 'bed',\n",
       " 'clair',\n",
       " 'sr',\n",
       " 'follow',\n",
       " 'ind',\n",
       " 'point',\n",
       " 'supply',\n",
       " 'later',\n",
       " 'pt',\n",
       " 'clothing',\n",
       " 'passenger',\n",
       " 'tomorrow',\n",
       " 'desire',\n",
       " 'league',\n",
       " 'suite',\n",
       " 'bo',\n",
       " 'states',\n",
       " 'central',\n",
       " 'net',\n",
       " 'body',\n",
       " 'tour',\n",
       " 'mortgage',\n",
       " 'super',\n",
       " 'te',\n",
       " 'blame',\n",
       " 'ix',\n",
       " 'location',\n",
       " 'throw',\n",
       " 'mil',\n",
       " 'accept',\n",
       " 'young',\n",
       " 'latvia',\n",
       " 'end',\n",
       " 'race',\n",
       " 'allow',\n",
       " 'maria',\n",
       " 'lo',\n",
       " 'migration',\n",
       " 'pf',\n",
       " 'xd',\n",
       " 'kl',\n",
       " 'sedan',\n",
       " 'golf',\n",
       " 'repair',\n",
       " 'va',\n",
       " 'passport',\n",
       " 'processing',\n",
       " 'latvian',\n",
       " 'scout',\n",
       " 'coupon',\n",
       " 'situation',\n",
       " 'representative',\n",
       " 'panel',\n",
       " 'mile',\n",
       " 'loan',\n",
       " 'rv',\n",
       " 'suit',\n",
       " 'previous',\n",
       " 'movement',\n",
       " 'ter',\n",
       " 'band',\n",
       " 'explain',\n",
       " 'guide',\n",
       " 'australian',\n",
       " 'near',\n",
       " 'lawyer',\n",
       " 'dis',\n",
       " 'farmer',\n",
       " 'support',\n",
       " 'pc',\n",
       " 'pole',\n",
       " 'ut',\n",
       " 'tin',\n",
       " 'brick',\n",
       " 'beach',\n",
       " 'south',\n",
       " 'outside',\n",
       " 'ip',\n",
       " 'route',\n",
       " 'fire',\n",
       " 'tf',\n",
       " 'bid',\n",
       " 'unrra',\n",
       " 'branch',\n",
       " 'premise',\n",
       " 'ao',\n",
       " 'cl',\n",
       " 'close',\n",
       " 'rs',\n",
       " 'ih',\n",
       " 'bungalow',\n",
       " 'asset',\n",
       " 'ct',\n",
       " 'russians',\n",
       " 'corp',\n",
       " 'regulation',\n",
       " 'clerk',\n",
       " 'interment',\n",
       " 'hit',\n",
       " 'pacific',\n",
       " 'paper',\n",
       " 'immi',\n",
       " 'redemption',\n",
       " 'management',\n",
       " 'convention',\n",
       " 'ballroom',\n",
       " 'state',\n",
       " 'fox',\n",
       " 'holiday',\n",
       " 'personnel',\n",
       " 'conservative',\n",
       " 'college',\n",
       " 'account',\n",
       " 'parking',\n",
       " 'justice',\n",
       " 'furlong',\n",
       " 'cf',\n",
       " 'om',\n",
       " 'manufacturer',\n",
       " 'convener',\n",
       " 'owner',\n",
       " 'inn',\n",
       " 'plant',\n",
       " 'dealer',\n",
       " 'dead',\n",
       " 'delegate',\n",
       " 'cd',\n",
       " 'especially',\n",
       " 'ship',\n",
       " 'en',\n",
       " 'lose',\n",
       " 'payment',\n",
       " 'tip',\n",
       " 'duty',\n",
       " 'kitty',\n",
       " 'lr',\n",
       " 'tk',\n",
       " 'permanent',\n",
       " 'typist',\n",
       " 'dance',\n",
       " 'sterling',\n",
       " 'page',\n",
       " 'wheat',\n",
       " 'away',\n",
       " 'use',\n",
       " 'opinion',\n",
       " 'br',\n",
       " 'investment',\n",
       " 'benefit',\n",
       " 'plea',\n",
       " 'estonian',\n",
       " 'bv',\n",
       " '2nd',\n",
       " 'clean',\n",
       " 'rio',\n",
       " 'ei',\n",
       " 'pool',\n",
       " 'av',\n",
       " 'queen',\n",
       " 'reply',\n",
       " 'oa',\n",
       " 'ff',\n",
       " 'decision',\n",
       " 'ls',\n",
       " 'croll',\n",
       " 'fleming',\n",
       " 'abbott',\n",
       " 'ng',\n",
       " 'leader',\n",
       " 'reasonable',\n",
       " 'fisherman',\n",
       " 'ger',\n",
       " 've',\n",
       " 'distribute',\n",
       " 'ukraine',\n",
       " 'commercial',\n",
       " 'hv',\n",
       " 'mn',\n",
       " 'blast',\n",
       " 'slum',\n",
       " 'fm',\n",
       " 'week',\n",
       " 'ce',\n",
       " 'lumber',\n",
       " 'aa',\n",
       " 'fashion',\n",
       " 'hr',\n",
       " 'ly',\n",
       " 'es',\n",
       " 'au',\n",
       " 'joy',\n",
       " 'essential',\n",
       " 'series',\n",
       " 'probably',\n",
       " 'responsible',\n",
       " 'figure',\n",
       " 'type',\n",
       " 'debenture',\n",
       " 'iw',\n",
       " 'water',\n",
       " 'guarantee',\n",
       " 'campbell',\n",
       " 'skilled',\n",
       " 'ccf',\n",
       " 'ami',\n",
       " 'holder',\n",
       " 'jo',\n",
       " 'thank',\n",
       " 'nw',\n",
       " 'mu',\n",
       " 'vv',\n",
       " 'quote',\n",
       " 'hot',\n",
       " 'qj',\n",
       " 'far',\n",
       " 'foreign',\n",
       " 'ore',\n",
       " 'advertiser',\n",
       " 'island',\n",
       " 'thought',\n",
       " 'education',\n",
       " 'political',\n",
       " 'de',\n",
       " 'ou',\n",
       " 'liner',\n",
       " 'williamson',\n",
       " 'attack',\n",
       " 'ideal',\n",
       " 'choice',\n",
       " 'den',\n",
       " 'commissioner',\n",
       " 'swiss',\n",
       " 'eye',\n",
       " 'chml',\n",
       " 'concern',\n",
       " 'mme',\n",
       " 'rcmp',\n",
       " 'medical',\n",
       " 'garden',\n",
       " 'permit',\n",
       " 'establish',\n",
       " 'ik',\n",
       " 'danforth',\n",
       " 'shoe',\n",
       " 'pete',\n",
       " 'ant',\n",
       " 'smile',\n",
       " 'festival',\n",
       " 'vj',\n",
       " 'jt',\n",
       " 'ib',\n",
       " 'senator',\n",
       " 'joint',\n",
       " 'ic',\n",
       " 'picture',\n",
       " 'luxury',\n",
       " 'mother',\n",
       " 'nm',\n",
       " 'rcyc',\n",
       " 'detail',\n",
       " 'source',\n",
       " 'automatic',\n",
       " 'mention',\n",
       " 'ion',\n",
       " 'lation',\n",
       " 'advise',\n",
       " 'quiet',\n",
       " 'burn',\n",
       " 'stenographer',\n",
       " 'fast',\n",
       " 'fish',\n",
       " 'js',\n",
       " 'ckey',\n",
       " 'remark',\n",
       " 'datum',\n",
       " 'category',\n",
       " 'appoint',\n",
       " 'print',\n",
       " 'genuine',\n",
       " 'lead',\n",
       " 'assist',\n",
       " 'amateur',\n",
       " 'praise',\n",
       " 'trend',\n",
       " 'century',\n",
       " 'cardinal',\n",
       " 'security',\n",
       " 'president',\n",
       " 'thousand',\n",
       " 'xn',\n",
       " 'court',\n",
       " 'training',\n",
       " 'publish',\n",
       " 'urge',\n",
       " 'chapel',\n",
       " 'section',\n",
       " 'extend',\n",
       " 'cemetery',\n",
       " 'qt',\n",
       " 'solicitor',\n",
       " 'free',\n",
       " 'hav',\n",
       " 'equip',\n",
       " 'kick',\n",
       " 'ear',\n",
       " 'create',\n",
       " 'y',\n",
       " 'standard',\n",
       " 'librarian',\n",
       " 'chief',\n",
       " 'record',\n",
       " 'ta',\n",
       " 'special',\n",
       " 'ted',\n",
       " 'cut',\n",
       " 'michael',\n",
       " 'accident',\n",
       " 'unable',\n",
       " 'sail',\n",
       " 'staff',\n",
       " 'favor',\n",
       " 'winter',\n",
       " 'press',\n",
       " 'formal',\n",
       " 'understand',\n",
       " 'basis',\n",
       " 'separate',\n",
       " 'stage',\n",
       " 'ibm',\n",
       " 'ms',\n",
       " 'understanding',\n",
       " 'dav',\n",
       " 'retire',\n",
       " 'municipal',\n",
       " 'vs',\n",
       " 'arm',\n",
       " 'set',\n",
       " 'traffic',\n",
       " 'truth',\n",
       " 'welcome',\n",
       " 'society',\n",
       " 'injury',\n",
       " 'democratic',\n",
       " 'geneva',\n",
       " 'ffl',\n",
       " 'town',\n",
       " 'rk',\n",
       " 'macdonald',\n",
       " 'common',\n",
       " 'discovery',\n",
       " 'william',\n",
       " 'tel',\n",
       " 'sf',\n",
       " 'frederick',\n",
       " 'hp',\n",
       " 'government',\n",
       " 'marry',\n",
       " 'lfi',\n",
       " 'purchase',\n",
       " 'brother',\n",
       " 'decease',\n",
       " 'consider',\n",
       " 'force',\n",
       " 'great',\n",
       " 'finally',\n",
       " 'chain',\n",
       " 'register',\n",
       " 'clothe',\n",
       " 'comment',\n",
       " 'ent',\n",
       " 'bl',\n",
       " 'heat',\n",
       " 'ef',\n",
       " 'experienced',\n",
       " 'til',\n",
       " 'prison',\n",
       " 'lithuania',\n",
       " 'electric',\n",
       " 'aid',\n",
       " 'tlon',\n",
       " 'voice',\n",
       " 'total',\n",
       " 'retirement',\n",
       " 'lk',\n",
       " 'tc',\n",
       " 'scholarship',\n",
       " 'ah',\n",
       " 'hn',\n",
       " 'neck',\n",
       " 'jn',\n",
       " 'mental',\n",
       " 'vice',\n",
       " 'leaf',\n",
       " 'shaw',\n",
       " 'community',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.term_highlighter.sorted_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba1b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d490ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4083799e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'person' in HRSystem.VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cbe5c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 30,694\n",
      "[('title', 396947), ('new', 359524), ('toronto', 347775), ('said', 277651), ('year', 267324), ('time', 247789), ('canada', 234967), ('ing', 226704), ('day', 224558), ('today', 221117)]\n",
      "Original vocab size: 10,000\n"
     ]
    }
   ],
   "source": [
    "# ## FOR CHANGE ONCE I HAVE THE FINAL \n",
    "# lines = open('../04. Model of DP/precomputed/freq.txt').read().splitlines()\n",
    "\n",
    "\n",
    "# freq = ([line.split(';') for line in lines])\n",
    "# print(f'Original vocab size: {len(freq):,}')\n",
    "# freq = [(word,int(freq)) for word,freq in freq if len(word)>2]\n",
    "# freq = sorted(freq, key=lambda x: x[1], reverse=True)[:10000]\n",
    "# print(freq[:10])\n",
    "# vocab = [word for word,_ in freq]\n",
    "# vocab\n",
    "# word2index = dict([(word,index) for index, word in enumerate(vocab)])\n",
    "\n",
    "# writer = open('../04. Model of DP/precomputed/vocab.txt', 'w')\n",
    "# writer.write('\\n'.join(vocab)+'\\n')\n",
    "# writer.close()\n",
    "# del(vocab,freq) \n",
    " \n",
    "# print(f'Original vocab size: {len(word2index):,}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553874a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b70b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1288605023\n",
    "# 1282700610\n",
    "# 1283089935\n",
    "# 1287452129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c880fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288605023\n",
      "1282700610\n",
      "1283089935\n",
      "1287452129\n"
     ]
    }
   ],
   "source": [
    "# from utils.tdmstudio import TDMStudio\n",
    "# count=4\n",
    "# for item in system.unlabeled_data:\n",
    "#     title,text = TDMStudio.get_title_and_text(item.filename())\n",
    "#     if 'argentina' in f'{title}. {text}'.lower():\n",
    "#         print(item.id_)\n",
    "#         count-=1\n",
    "#     if count==0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d265bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d73529d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      params  mean accuracy  mean precision  mean recall   mean f1\n",
      "0  {'C': 30}           0.55        0.540952     0.437778  0.470238\n",
      "1  {'C': 40}           0.54        0.526667     0.437778  0.464356\n",
      "2  {'C': 50}           0.53        0.500000     0.457778  0.470626\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import cross_validate\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# parameters = { 'C':[30,40, 50]}\n",
    "# svc = SVC(kernel='rbf')\n",
    "\n",
    "# # parameters = {'C':[1,2,3,4,5,6], 'degree':[1,2,3,4,5,6,7]}\n",
    "# # svc = SVC(kernel='poly')\n",
    "# clf = GridSearchCV(svc, parameters,scoring=['f1','accuracy','precision', 'recall'], cv=5,verbose=0, refit='f1')\n",
    "# X = np.random.rand(100,5)\n",
    "# y = np.random.rand(100,)*100\n",
    "# y = y.astype('int')\n",
    "# y = y %2\n",
    "# rta = clf.fit(X,y)\n",
    "# pd.DataFrame(results.cv_results_)\n",
    "# df = (pd.DataFrame(rta.cv_results_)[[\"params\",\"mean_test_accuracy\", \"mean_test_precision\",\"mean_test_recall\",\"mean_test_f1\"]])\n",
    "# df.columns=['params','mean accuracy', 'mean precision','mean recall','mean f1',]\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb8b188f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>rank_test_precision</th>\n",
       "      <th>split0_test_recall</th>\n",
       "      <th>split1_test_recall</th>\n",
       "      <th>split2_test_recall</th>\n",
       "      <th>split3_test_recall</th>\n",
       "      <th>split4_test_recall</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>rank_test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>30</td>\n",
       "      <td>{'C': 30}</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046380</td>\n",
       "      <td>3</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.408889</td>\n",
       "      <td>0.142534</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.011826</td>\n",
       "      <td>0.005670</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>40</td>\n",
       "      <td>{'C': 40}</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054007</td>\n",
       "      <td>1</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.428889</td>\n",
       "      <td>0.159876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>50</td>\n",
       "      <td>{'C': 50}</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059792</td>\n",
       "      <td>2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.428889</td>\n",
       "      <td>0.159876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.004550      0.002883         0.006639        0.003300      30   \n",
       "1       0.009431      0.011826         0.005670        0.002318      40   \n",
       "2       0.002962      0.000221         0.004195        0.000438      50   \n",
       "\n",
       "      params  split0_test_f1  split1_test_f1  split2_test_f1  split3_test_f1  \\\n",
       "0  {'C': 30}        0.400000        0.454545             0.5        0.266667   \n",
       "1  {'C': 40}        0.421053        0.521739             0.5        0.266667   \n",
       "2  {'C': 50}        0.421053        0.521739             0.5        0.250000   \n",
       "\n",
       "   ...  std_test_precision  rank_test_precision  split0_test_recall  \\\n",
       "0  ...            0.046380                    3            0.444444   \n",
       "1  ...            0.054007                    1            0.444444   \n",
       "2  ...            0.059792                    2            0.444444   \n",
       "\n",
       "   split1_test_recall  split2_test_recall  split3_test_recall  \\\n",
       "0                 0.5                 0.6                 0.2   \n",
       "1                 0.6                 0.6                 0.2   \n",
       "2                 0.6                 0.6                 0.2   \n",
       "\n",
       "   split4_test_recall  mean_test_recall  std_test_recall  rank_test_recall  \n",
       "0                 0.3          0.408889         0.142534                 3  \n",
       "1                 0.3          0.428889         0.159876                 1  \n",
       "2                 0.3          0.428889         0.159876                 1  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rta.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85793432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-23 18:23:58.195964 [ \u001b[1;94mINFO\u001b[0m  ] Number of unlabeled documents:  1,934,909\n",
      "2022-03-23 18:23:58.196109 [ \u001b[1;94mINFO\u001b[0m  ] Number of labeled documents:      114,492\n",
      "2022-03-23 18:23:58.196144 [ \u001b[1;94mINFO\u001b[0m  ] Number of suggestions:                  0\n",
      "\n",
      "2022-03-23 18:23:58.206889 [ \u001b[1;94mINFO\u001b[0m  ] Number of unlabeled documents:  1,934,909\n",
      "2022-03-23 18:23:58.207013 [ \u001b[1;94mINFO\u001b[0m  ] Number of labeled documents:      114,492\n",
      "2022-03-23 18:23:58.207058 [ \u001b[1;94mINFO\u001b[0m  ] Number of suggestions:                  0\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision  test_recall   test_f1\n",
      "0  23.818077    0.079863       0.996393        0.828647     0.602446  0.658534\n",
      "2022-03-23 18:32:23.618718 [ \u001b[1;94mINFO\u001b[0m  ] Estimated number of relevant articles found: 37555\n",
      "2022-03-23 18:32:23.848950 [ \u001b[1;94mINFO\u001b[0m  ] Number of unlabeled documents:  1,934,899\n",
      "2022-03-23 18:32:23.849091 [ \u001b[1;94mINFO\u001b[0m  ] Number of labeled documents:      114,492\n",
      "2022-03-23 18:32:23.849112 [ \u001b[1;94mINFO\u001b[0m  ] Number of suggestions:                 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d751c32a85ae402b8608e19f2dd1e66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad26bac3d083414692135a57e22f9b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Relevant', style=ButtonStyle()), Button(description='Irrelev…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfd4acff2e94a24b2dba58e68d31392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# system.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92f2d875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.673687</td>\n",
       "      <td>0.474377</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.709402</td>\n",
       "      <td>0.731278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.503884</td>\n",
       "      <td>0.540821</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.732759</td>\n",
       "      <td>0.776256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.524282</td>\n",
       "      <td>0.557241</td>\n",
       "      <td>0.961295</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.698276</td>\n",
       "      <td>0.746544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.468833</td>\n",
       "      <td>0.548861</td>\n",
       "      <td>0.961295</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.751131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.473676</td>\n",
       "      <td>0.544166</td>\n",
       "      <td>0.966197</td>\n",
       "      <td>0.788136</td>\n",
       "      <td>0.801724</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  test_precision  test_recall   test_f1\n",
       "0  2.673687    0.474377       0.957072        0.754545     0.709402  0.731278\n",
       "1  2.503884    0.540821       0.965517        0.825243     0.732759  0.776256\n",
       "2  2.524282    0.557241       0.961295        0.801980     0.698276  0.746544\n",
       "3  2.468833    0.548861       0.961295        0.790476     0.715517  0.751131\n",
       "4  2.473676    0.544166       0.966197        0.788136     0.801724  0.794872"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(rta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "711b630b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.52887244, 0.53309326, 0.96227533, 0.79207603, 0.73153551,\n",
       "        0.76001601]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(results.values,axis=0).reshape(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d137a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a731d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-21 17:44:52.618183 [ \u001b[1;94mINFO\u001b[0m  ] Number of unlabeled documents:  2,057,868\n",
      "2022-03-21 17:44:52.619272 [ \u001b[1;94mINFO\u001b[0m  ] Number of labeled documents:        4,695\n"
     ]
    }
   ],
   "source": [
    "from utils.models import DataItem\n",
    "import os\n",
    "unlabeled_data = []\n",
    "labeled_data = []\n",
    "\n",
    "GM1 = '/home/ec2-user/SageMaker/data/GM_all_1945_1956/'\n",
    "GM2 = '/home/ec2-user/SageMaker/data/GM_all_1957-1967/'\n",
    "\n",
    "unlabeled_data = [DataItem(GM1+file_) for file_ in os.listdir(GM1)] + [DataItem(GM2+file_) for file_ in os.listdir(GM2)]\n",
    "labeled_data = []\n",
    "for line in open('labeled_data.csv').read().splitlines()[1:]:\n",
    "    id_,label = line.split(';')\n",
    "    item = DataItem(id_)\n",
    "    if label=='R':\n",
    "        item.set_relevant()\n",
    "    else:\n",
    "        item.set_irrelevant()\n",
    "        assert label=='I'\n",
    "    if item.has_vector():\n",
    "        labeled_data.append(item)\n",
    "# labeled_data = [DataItem(line.split(';')[0]) for line in open('labeled_data.csv').read().splitlines()[1:]]\n",
    "\n",
    "info(f'Number of unlabeled documents: {len(unlabeled_data):10,}')\n",
    "info(f'Number of labeled documents:   {len(labeled_data):10,}')\n",
    "# os.listdir(GM1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5ad976e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-21 18:05:11.185323 [ \u001b[1;94mINFO\u001b[0m  ] Number of unlabeled documents:  1,556,455\n"
     ]
    }
   ],
   "source": [
    "unlabeled_data = [item for item in unlabeled_data if item.has_vector()]\n",
    "info(f'Number of unlabeled documents: {len(unlabeled_data):10,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5414a8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.7 s, sys: 532 ms, total: 5.23 s\n",
      "Wall time: 7min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bdffab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_data[0].has_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99c3525b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count = 0\n",
    "# for item in unlabeled_data:\n",
    "    \n",
    "# clf.predict(DataItem.get_X([unlabeled_data[205]], type_=DataItem.TYPE_GLOVE600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e678acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-21 18:53:44.723528 [ \u001b[1;94mINFO\u001b[0m  ] Number of unlabeled documents:  1,776,413\n",
      "2022-03-21 18:53:44.730451 [ \u001b[1;94mINFO\u001b[0m  ] Number of labeled documents:        5,739\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22417db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836dc5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daded2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589327f794464f5e98c7d6baa4313fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 2 Examples annotated.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef9db6ab2f04510886443c602fdd807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Relevant', style=ButtonStyle()), Button(description='Irrelev…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531af0e0b451466eb97e9f8ef67db993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation done.\n"
     ]
    }
   ],
   "source": [
    "import myversions.pigeonXT as pixt\n",
    "\n",
    "annotations = pixt.annotate(\n",
    "            [\"hello world\", \"Some other text.\"],\n",
    "            options = ['Relevant', 'Irrelevant'],\n",
    "            stop_at_last_example=False,\n",
    "            display_fn=html,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "428e7da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Relevant\n",
       "1    Relevant\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c03396f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>changed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello world</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other stuff</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       example  changed label\n",
       "0  hello world    False      \n",
       "1  other stuff    False      "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pigeonXT as pixt2\n",
    "pixt2.annotate(['hello world', 'other stuff'], options=['R', 'N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7979e57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataItem(id=1293118416, source=GM1, label=U)\n"
     ]
    }
   ],
   "source": [
    "print(DataItem(open('labeled_data.csv', 'r').read().splitlines()[1:][0].split(';')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1cd95ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1293118416'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line.split(';')[0] for line in open('labeled_data.csv').read().splitlines()[1:]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9c7de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-21 16:23:35.503167 [ \u001b[1;94mINFO\u001b[0m  ] Number of unlabeled documents:  1,556,455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1556455"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1e86eb8",
   "metadata": {},
   "source": [
    "### OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a50a5ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found: ['2459964104', '1411697642', '2122281371', '1136691129', '1242257052', '1239753620', '1238204962', '2459666609', '2122279956', '1151348424', '1238440920', '1222379804', '1143160388']\n",
      "2022-03-21 16:28:55.030601 [ \u001b[1;94mINFO\u001b[0m  ] len(relevant_set)   = 581\n",
      "2022-03-21 16:28:55.030799 [ \u001b[1;94mINFO\u001b[0m  ] len(irrelevant_set) = 6523\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import re\n",
    "# from utils.general import id2file\n",
    "\n",
    "# second_round_data = [linea.strip().split(';') for linea in  open('../04. Model of DP/second_roud_labels.csv','r').read().splitlines()]\n",
    "# irrelevant_set = set([id_ for id_,label in second_round_data if label=='I'])\n",
    "# relevant_set = set([id_ for id_,label in second_round_data if label=='R'])\n",
    "\n",
    "\n",
    "# # Loading new_data\n",
    "# new_data = [line.split(';') for line in open('../04. Model of DP/new_data.csv').read().splitlines()]\n",
    "# relevant_set = relevant_set.union(set([id_ for id_,label in new_data if label.strip()=='R']))\n",
    "# irrelevant_set = irrelevant_set.union(set([id_ for id_,label in new_data if label.strip()=='I']))\n",
    "\n",
    "# # Loading original data\n",
    "# DP_examples_dirpath = '/home/ec2-user/SageMaker/mariano/notebooks/04. Model of DP/DP-relevant articles/'\n",
    "\n",
    "# first_data = []\n",
    "# for dirpath, dirnames, filenames in os.walk(DP_examples_dirpath):\n",
    "#     for filename in filenames:\n",
    "#         content = open(os.path.join(dirpath,filename),'r').read()\n",
    "#         ids = re.findall('/docview/([^/]*)/',content)\n",
    "#         relevant_set = relevant_set.union(set(ids))\n",
    "    \n",
    "# # articles containg DP and Canada from that period, that were not deteted by Serperi\n",
    "# GM_dp_dirpath = '/home/ec2-user/SageMaker/data/GM_DP_and_Canada1945_1967/'\n",
    "\n",
    "# files = os.listdir(GM_dp_dirpath)\n",
    "\n",
    "# irrelevant_set = irrelevant_set.union([file_[:-4] for file_ in files if file_[:-4] not in relevant_set and file_.endswith('.xml')])\n",
    "\n",
    "# not_found=[]\n",
    "# for id_ in list(relevant_set)+list(irrelevant_set):\n",
    "#     if id2file(id_) is None:\n",
    "#         not_found.append(id_)\n",
    "# print(f'Not found: {not_found}')\n",
    "# for id_ in not_found:\n",
    "#     relevant_set = relevant_set.difference(set(not_found))\n",
    "#     irrelevant_set = irrelevant_set.difference(set(not_found))\n",
    "    \n",
    "# info(f'len(relevant_set)   = {len(relevant_set)}')\n",
    "# info(f'len(irrelevant_set) = {len(irrelevant_set)}')\n",
    "\n",
    "# import pandas as pd \n",
    "\n",
    "# df = pd.DataFrame(list(relevant_set)+list(irrelevant_set),columns=['id'])\n",
    "# df['label']='I'\n",
    "# df.iloc[:len(relevant_set),1]='R'\n",
    "# df.to_csv('labeled_data.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae825ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6523\n"
     ]
    }
   ],
   "source": [
    "!grep I labeled_data.csv  |wc -l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d941fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "438599fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'DataItem' has no attribute 'TYPE_BOW'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4431/3434096655.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDataItem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTYPE_BOW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'DataItem' has no attribute 'TYPE_BOW'"
     ]
    }
   ],
   "source": [
    "\n",
    "DataItem.TYPE_BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9ba7f21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataItem(id=1323614655, source=GM1, label=U)\n",
      "DataItem(id=1287437740, source=GM1, label=U)\n"
     ]
    }
   ],
   "source": [
    "item1 = DataItem('/home/ec2-user/SageMaker/data/GM_all_1945_1956/1323614655.xml')\n",
    "item2 = DataItem('1287437740','GM1')\n",
    "print(item1)\n",
    "print(item2)\n",
    "# item1.label = DataItem.REL_LABEL\n",
    "# item2.label = DataItem.IREL_LABEL\n",
    "# DataItem.get_X([item1,item2], type_=DataItem.TYPE_GLOVE600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ca50f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "674cda88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# item1 = DataItem('/home/ec2-user/SageMaker/data/GM_all_1945_1956/1323614655.xml')\n",
    "# item2 = DataItem('1287437740','GM1')\n",
    "# item1.label = DataItem.REL_LABEL\n",
    "# item2.label = DataItem.IREL_LABEL\n",
    "# X = DataItem.get_X([item1, item2], type_=DataItem.TYPE_GLOVE600)\n",
    "# y = DataItem.get_y([item1, item2])\n",
    "# clf = SVC()\n",
    "# clf.fit(X, y)\n",
    "# print(clf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6debbff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "629d4a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b00c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c34111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a37d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7d092e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# item1.vector(type_='glove300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd7d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imm",
   "language": "python",
   "name": "imm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
